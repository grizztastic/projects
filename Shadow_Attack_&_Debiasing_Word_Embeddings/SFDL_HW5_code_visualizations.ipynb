{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SFDL_HW5_code_visualizations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLIRGbC3D34Q",
        "colab_type": "code",
        "outputId": "a3ce3673-eb70-4c7f-8334-4cb085cad78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!unzip hw5_part_two_release.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  hw5_part_two_release.zip\n",
            "  inflating: data/questions-words.txt  \n",
            "  inflating: data/definitional_pairs.json  \n",
            "  inflating: data/equalize_pairs.json  \n",
            "  inflating: data/gender_specific_full.json  \n",
            "  inflating: data/profession_words.json  \n",
            "  inflating: hw5_part2.ipynb         \n",
            "  inflating: hw5_part1.py            \n",
            "  inflating: hw5_part1_utils.py      \n",
            "  inflating: hw5_part2.py            \n",
            "  inflating: hw5_part3.py            \n",
            "  inflating: adult.npz               \n",
            "  inflating: homework.pdf            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epvizLkvEwVe",
        "colab_type": "code",
        "outputId": "82619f93-5d26-4645-f82d-6d9afc92ac60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYCuTB8FTGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "import hw5_part1_utils\n",
        "\n",
        "from typing import Tuple\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4vaHH-I3c7l",
        "colab_type": "text"
      },
      "source": [
        "Written Exercise 4 code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgKh_DviE1ab",
        "colab_type": "code",
        "outputId": "90d98d21-03b3-4dc1-a680-36ab671f3e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# YOUR IMPLEMENTATION FOR THE SHADOW MODEL ATTACK GOES HERE ###################\n",
        "\n",
        "\n",
        "def synthesize_attack_data(\n",
        "    target_model: hw5_part1_utils.TargetModel,\n",
        "    shadow_data: np.ndarray,\n",
        "    shadow_labels: np.ndarray,\n",
        "    num_shadow_models: int = 4\n",
        "):\n",
        "    \"\"\"Synthesize attack data.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        target_model {TargetModel} -- an instance of the TargetModel class;\n",
        "          behaves as a keras model but additionally has a train_shadow_model\n",
        "          function, which takes a subset of the shadow data and labels and\n",
        "          returns a model with identical architecture and hyperparameters to\n",
        "          the original target model, but that is trained on the given shadow\n",
        "          data.\n",
        "\n",
        "        shadow_data {np.ndarray} -- data available to the attack to train\n",
        "          shadow models. If the arget model's training set is size N x D,\n",
        "          shadow_data is 2N x D.\n",
        "\n",
        "        shadow_labels {np.ndarray} -- the corresponding labels to the\n",
        "          shadow_data, given as a numpy array of 2N integers in the range 0 to\n",
        "          C where C is the number of classes.\n",
        "\n",
        "        num_shadow_models {int} -- the number of shadow models to use when\n",
        "          constructing the attack model's dataset.\n",
        "\n",
        "    Returns: three np.ndarrays; let M = 2N * num_shadow_models\n",
        "\n",
        "        attack_data {np.ndarray} [M, 2C] -- shadow data label probability and\n",
        "           label one-hot\n",
        "\n",
        "        attack_classes {np.ndarray} [M, 1 of {0,1,...,C-1}] -- shadow data\n",
        "           labels\n",
        "\n",
        "        attack_labels {np.ndarray} [M, 1 of {0,1}] -- attack data labels\n",
        "           (training membership)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    C = shadow_labels.max() + 1\n",
        "\n",
        "    attack_data: np.ndarray = None\n",
        "    attack_classes: np.ndarray = None\n",
        "    attack_labels: np.ndarray = None\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    in_data = []\n",
        "    out_data = []\n",
        "    shadow_data_classes = []\n",
        "\n",
        "    for i in tqdm(\n",
        "        range(num_shadow_models),\n",
        "        desc=\"training shadow models\",\n",
        "        unit=\"split\"\n",
        "    ):\n",
        "\n",
        "        split = hw5_part1_utils.DataSplit(shadow_labels, seed=i)\n",
        "\n",
        "        shadow_model = target_model.train_shadow_model(\n",
        "            shadow_data[split.in_idx], shadow_labels[split.in_idx],\n",
        "            # shadow_data[split.out_idx], shadow_labels[split.out_idx]\n",
        "            # validation data\n",
        "        )\n",
        "\n",
        "        in_pred = shadow_model.predict(shadow_data[split.in_idx])\n",
        "        in_onehot = to_categorical(\n",
        "            shadow_labels[split.in_idx], C\n",
        "        )\n",
        "        in_data.append(np.concatenate(\n",
        "            (in_pred, in_onehot),\n",
        "            axis=1)\n",
        "        )\n",
        "\n",
        "        out_pred = shadow_model.predict(shadow_data[split.out_idx])\n",
        "        out_onehot = to_categorical(\n",
        "            shadow_labels[split.out_idx], C\n",
        "        )\n",
        "        out_data.append(np.concatenate(\n",
        "            (out_pred, out_onehot),\n",
        "            axis=1)\n",
        "        )\n",
        "        shadow_data_classes.append(shadow_labels[split.in_idx])\n",
        "        shadow_data_classes.append(shadow_labels[split.out_idx])\n",
        "\n",
        "    in_data = np.concatenate(in_data)\n",
        "    out_data = np.concatenate(out_data)\n",
        "\n",
        "    attack_data = np.concatenate((in_data, out_data))\n",
        "\n",
        "    attack_labels = np.concatenate((\n",
        "        np.ones(len(in_data)),\n",
        "        np.zeros(len(out_data)))\n",
        "    )\n",
        "\n",
        "    attack_classes = np.concatenate(shadow_data_classes)\n",
        "\n",
        "    ###\n",
        "\n",
        "    return attack_data, attack_classes, attack_labels\n",
        "\n",
        "\n",
        "def build_attack_models(\n",
        "    target_model: hw5_part1_utils.TargetModel,\n",
        "    shadow_data: np.ndarray,\n",
        "    shadow_labels: np.ndarray,\n",
        "    num_shadow_models: int = 4,\n",
        "    batch_size=2048,\n",
        "    epochs=32\n",
        "):\n",
        "    \"\"\"Build attacker models.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        target_model {TargetModel} -- an instance of the TargetModel class;\n",
        "          behaves as a keras model but additionally has a train_shadow_model\n",
        "          function, which takes a subset of the shadow data and labels and\n",
        "          returns a model with identical architecture and hyperparameters to\n",
        "          the original target model, but that is trained on the given shadow\n",
        "          data.\n",
        "\n",
        "        shadow_data {np.ndarray} -- data available to the attack to train\n",
        "          shadow models. If the arget model's training set is size N x D,\n",
        "          shadow_data is 2N x D.\n",
        "\n",
        "        shadow_labels {np.ndarray} -- the corresponding labels to the\n",
        "          shadow_data, given as a numpy array of 2N integers in the range 0 to\n",
        "          C where C is the number of classes.\n",
        "\n",
        "        num_shadow_models {int} -- the number of shadow models to use when\n",
        "          constructing the attack model's dataset.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "        {tuple} -- a tuple of C keras models, where the c^th model predicts the\n",
        "        probability that an instance of class c was a training set member.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    attack_data, attack_classes, attack_labels = \\\n",
        "        synthesize_attack_data(\n",
        "            target_model,\n",
        "            shadow_data,\n",
        "            shadow_labels,\n",
        "            num_shadow_models=4\n",
        "        )\n",
        "\n",
        "    # to return\n",
        "    attack_models: Tuple[Model] = None\n",
        "\n",
        "    C = shadow_labels.max() + 1\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    # Define the attack model architecture.\n",
        "    # def get_attack_model_architecture_1():\n",
        "    #     attack_x = Input((2 * C,))\n",
        "    #     attack_y = Dense(128, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(64, activation='relu')(attack_y)\n",
        "    #     attack_y = Dense(32, activation='relu')(attack_y)\n",
        "    #     attack_y = Dense(10, activation='relu')(attack_y)\n",
        "    #     attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "    #     attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "    #     attack_model.compile(\n",
        "    #         optimizer='adam',\n",
        "    #         loss='binary_crossentropy',\n",
        "    #         metrics=['accuracy']\n",
        "    #     )\n",
        "\n",
        "    #     return attack_model\n",
        "\n",
        "        # Define the attack model architecture.\n",
        "    def get_attack_model_architecture_2():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(4 * C, activation='relu')(attack_x)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "\n",
        "        # Define the attack model architecture.\n",
        "    # def get_attack_model_architecture_3():\n",
        "    #     attack_x = Input((2 * C,))\n",
        "    #     attack_y = Dense(128, activation='relu')(attack_x)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(64, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(32, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(32, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "    #     attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "    #     attack_model.compile(\n",
        "    #         optimizer='adam',\n",
        "    #         loss='binary_crossentropy',\n",
        "    #         metrics=['accuracy']\n",
        "    #     )\n",
        "\n",
        "    #     return attack_model\n",
        "    \n",
        "    #     # Define the attack model architecture.\n",
        "    # def get_attack_model_architecture_4():\n",
        "    #     attack_x = Input((2 * C,))\n",
        "    #     attack_y = Dense(20, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(16, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(12, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(8, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(4, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(2, activation='relu')(attack_x)\n",
        "    #     attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "    #     attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "    #     attack_model.compile(\n",
        "    #         optimizer='adam',\n",
        "    #         loss='binary_crossentropy',\n",
        "    #         metrics=['accuracy']\n",
        "    #     )\n",
        "\n",
        "    #     return attack_model\n",
        "\n",
        "    #     # Define the attack model architecture.\n",
        "    # def get_attack_model_architecture_5():\n",
        "    #     attack_x = Input((2 * C,))\n",
        "    #     attack_y = Dense(48, activation='relu')(attack_x)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(48, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(32, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(16, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(10, activation='relu')(attack_y)\n",
        "    #     attack_y = Dropout(0.2)(attack_y)\n",
        "    #     attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "    #     attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "    #     attack_model.compile(\n",
        "    #         optimizer='adam',\n",
        "    #         loss='binary_crossentropy',\n",
        "    #         metrics=['accuracy']\n",
        "    #     )\n",
        "\n",
        "    #     return attack_model\n",
        "\n",
        "    # Train the attack model. We have one model per ground truth class.\n",
        "    # ret_models_1 = []\n",
        "    ret_models_2 = []\n",
        "    # ret_models_3 = []\n",
        "    # ret_models_4 = []\n",
        "    # ret_models_5 = []\n",
        "    for c in tqdm(range(C), desc=\"training attack models\", unit=\"class\"):\n",
        "        # attack_model_1 = get_attack_model_architecture_1()\n",
        "\n",
        "        # attack_model_1.fit(\n",
        "        #     attack_data[attack_classes == c],\n",
        "        #     attack_labels[attack_classes == c],\n",
        "        #     batch_size=batch_size,\n",
        "        #     verbose=0,\n",
        "        #     epochs=epochs\n",
        "        # )\n",
        "\n",
        "        # ret_models_1.append(attack_model_1)\n",
        "\n",
        "        attack_model_2 = get_attack_model_architecture_2()\n",
        "\n",
        "        attack_model_2.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_2.append(attack_model_2)\n",
        "\n",
        "        # attack_model_3 = get_attack_model_architecture_3()\n",
        "\n",
        "        # attack_model_3.fit(\n",
        "        #     attack_data[attack_classes == c],\n",
        "        #     attack_labels[attack_classes == c],\n",
        "        #     batch_size=batch_size,\n",
        "        #     verbose=0,\n",
        "        #     epochs=epochs\n",
        "        # )\n",
        "\n",
        "        # ret_models_3.append(attack_model_3)\n",
        "\n",
        "        # attack_model_4 = get_attack_model_architecture_4()\n",
        "\n",
        "        # attack_model_4.fit(\n",
        "        #     attack_data[attack_classes == c],\n",
        "        #     attack_labels[attack_classes == c],\n",
        "        #     batch_size=batch_size,\n",
        "        #     verbose=0,\n",
        "        #     epochs=epochs\n",
        "        # )\n",
        "\n",
        "        # ret_models_4.append(attack_model_4)\n",
        "\n",
        "        # attack_model_5 = get_attack_model_architecture_5()\n",
        "\n",
        "        # attack_model_5.fit(\n",
        "        #     attack_data[attack_classes == c],\n",
        "        #     attack_labels[attack_classes == c],\n",
        "        #     batch_size=batch_size,\n",
        "        #     verbose=0,\n",
        "        #     epochs=epochs\n",
        "        # )\n",
        "\n",
        "        # ret_models_5.append(attack_model_5)\n",
        "\n",
        "    # attack_models_1 = tuple(ret_models_1)\n",
        "    attack_models_2 = tuple(ret_models_2)\n",
        "    # attack_models_3 = tuple(ret_models_3)\n",
        "    # attack_models_4 = tuple(ret_models_4)\n",
        "    # attack_models_5 = tuple(ret_models_5)\n",
        "\n",
        "    ###\n",
        "\n",
        "    # return attack_models_1, attack_models_2, attack_models_3, attack_models_4, attack_models_5\n",
        "    return attack_models_2\n",
        "\n",
        "\n",
        "def evaluate_membership(attack_models, y_pred, y):\n",
        "    \"\"\"Evaluate the attacker about the membership inference\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        attack_model {tuple} -- a tuple of C keras models, where C is the\n",
        "          number of classes.\n",
        "\n",
        "        y_pred {np.ndarray} -- an N x C numpy array with the predictions of the\n",
        "          model on the N instances we are performing the inference attack on.\n",
        "\n",
        "        y {np.ndarray} -- the true labels for each of the instances given as a\n",
        "          numpy array of N integers.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "        {np.ndarray} -- an array of N floats in the range [0,1] representing\n",
        "          the estimated probability that each of the N given instances is a\n",
        "          training set member.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # To return\n",
        "    preds: np.ndarray = None\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "    attack_in = np.concatenate((y_pred, to_categorical(y)), axis=1)\n",
        "\n",
        "    preds = np.zeros(y.shape)\n",
        "\n",
        "    for c in tqdm(range(len(attack_models)),\n",
        "                  desc=\"evaluating submodels\",\n",
        "                  unit=\"class\"):\n",
        "\n",
        "        preds[y == c] = attack_models[c].predict(attack_in[y == c])[0]\n",
        "\n",
        "    ###\n",
        "\n",
        "    return preds\n",
        "\n",
        "# YOU DO NOT NEED TO MODIFY THE REST OF THIS CODE. ############################\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the dataset.\n",
        "    data = hw5_part1_utils.CIFARData()\n",
        "\n",
        "    # Make a target model for the dataset.\n",
        "    target_model_epochs = [12, 24, 36, 48, 60, 72, 84, 96, 108]\n",
        "    for i in range(len(target_model_epochs)):\n",
        "        target_model = \\\n",
        "            hw5_part1_utils.CIFARModel(\n",
        "                epochs=target_model_epochs[i],\n",
        "                batch_size=2048,\n",
        "                noload=True, # prevents loading an existing pre-trained target\n",
        "                            # model\n",
        "            ).init(\n",
        "                data.train, data.labels_train,\n",
        "                # data.test, data.labels_test # validation data\n",
        "            )\n",
        "        print(\"\\nTarget Model Epochs: \", target_model_epochs[i])\n",
        "        # tqdm.write('Building attack model...')\n",
        "        # attack_models_1, attack_models_2, attack_models_3, attack_models_4, attack_models_5 = build_attack_models(\n",
        "        #     target_model,\n",
        "        #     data.shadow,\n",
        "        #     data.labels_shadow\n",
        "        # )\n",
        "\n",
        "        tqdm.write('Building attack model...')\n",
        "        attack_models_2 = build_attack_models(\n",
        "            target_model,\n",
        "            data.shadow,\n",
        "            data.labels_shadow\n",
        "        )\n",
        "\n",
        "        tqdm.write('Evaluating target model...')\n",
        "        y_pred_in = target_model.predict(data.train)\n",
        "        y_pred_out = target_model.predict(data.test)\n",
        "\n",
        "        tqdm.write('  Train Accuracy: {:.4f}'.format(\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).mean()))\n",
        "        tqdm.write('  Test Accuracy:  {:.4f}'.format(\n",
        "            (y_pred_out.argmax(axis=1) == data.labels_test).mean()))\n",
        "\n",
        "        # in_preds_1 = evaluate_membership(\n",
        "        #     attack_models_1,\n",
        "        #     y_pred_in,\n",
        "        #     data.labels_train\n",
        "        # )\n",
        "        # out_preds_1 = evaluate_membership(\n",
        "        #     attack_models_1,\n",
        "        #     y_pred_out,\n",
        "        #     data.labels_test\n",
        "        # )\n",
        "\n",
        "        in_preds_2 = evaluate_membership(\n",
        "            attack_models_2,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_2 = evaluate_membership(\n",
        "            attack_models_2,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        # in_preds_3 = evaluate_membership(\n",
        "        #     attack_models_3,\n",
        "        #     y_pred_in,\n",
        "        #     data.labels_train\n",
        "        # )\n",
        "        # out_preds_3 = evaluate_membership(\n",
        "        #     attack_models_3,\n",
        "        #     y_pred_out,\n",
        "        #     data.labels_test\n",
        "        # )\n",
        "\n",
        "        # in_preds_4 = evaluate_membership(\n",
        "        #     attack_models_4,\n",
        "        #     y_pred_in,\n",
        "        #     data.labels_train\n",
        "        # )\n",
        "        # out_preds_4 = evaluate_membership(\n",
        "        #     attack_models_4,\n",
        "        #     y_pred_out,\n",
        "        #     data.labels_test\n",
        "        # )\n",
        "\n",
        "        # in_preds_5 = evaluate_membership(\n",
        "        #     attack_models_5,\n",
        "        #     y_pred_in,\n",
        "        #     data.labels_train\n",
        "        # )\n",
        "        # out_preds_5 = evaluate_membership(\n",
        "        #     attack_models_5,\n",
        "        #     y_pred_out,\n",
        "        #     data.labels_test\n",
        "        # )\n",
        "\n",
        "        # true_positives_1 = (in_preds_1 > 0.5).mean()\n",
        "        # true_negatives_1 = (out_preds_1 < 0.5).mean()\n",
        "        # attack_acc_1 = (true_positives_1 + true_negatives_1) / 2.\n",
        "\n",
        "        # attack_precision_1 = (in_preds_1 > 0.5).sum() / (\n",
        "        #     (in_preds_1 > 0.5).sum() + (out_preds_1 > 0.5).sum()\n",
        "        # )\n",
        "\n",
        "        true_positives_2 = (in_preds_2 > 0.5).mean()\n",
        "        true_negatives_2 = (out_preds_2 < 0.5).mean()\n",
        "        attack_acc_2 = (true_positives_2 + true_negatives_2) / 2.\n",
        "\n",
        "        attack_precision_2 = (in_preds_2 > 0.5).sum() / (\n",
        "            (in_preds_2 > 0.5).sum() + (out_preds_2 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "        # true_positives_3 = (in_preds_3 > 0.5).mean()\n",
        "        # true_negatives_3 = (out_preds_3 < 0.5).mean()\n",
        "        # attack_acc_3 = (true_positives_3 + true_negatives_3) / 2.\n",
        "\n",
        "        # attack_precision_3 = (in_preds_3 > 0.5).sum() / (\n",
        "        #     (in_preds_3 > 0.5).sum() + (out_preds_3 > 0.5).sum()\n",
        "        # )\n",
        "\n",
        "        # true_positives_4 = (in_preds_4 > 0.5).mean()\n",
        "        # true_negatives_4 = (out_preds_4 < 0.5).mean()\n",
        "        # attack_acc_4 = (true_positives_4 + true_negatives_4) / 2.\n",
        "\n",
        "        # attack_precision_4 = (in_preds_4 > 0.5).sum() / (\n",
        "        #     (in_preds_4 > 0.5).sum() + (out_preds_4 > 0.5).sum()\n",
        "        # )\n",
        "\n",
        "        # true_positives_5 = (in_preds_5 > 0.5).mean()\n",
        "        # true_negatives_5 = (out_preds_5 < 0.5).mean()\n",
        "        # attack_acc_5 = (true_positives_5 + true_negatives_5) / 2.\n",
        "\n",
        "        # attack_precision_5 = (in_preds_5 > 0.5).sum() / (\n",
        "        #     (in_preds_5 > 0.5).sum() + (out_preds_5 > 0.5).sum()\n",
        "        # )\n",
        "\n",
        "\n",
        "        wrongs_in = y_pred_in.argmax(axis=1) != data.labels_train\n",
        "        wrongs_out = y_pred_out.argmax(axis=1) != data.labels_test\n",
        "\n",
        "\n",
        "        # Compare to a baseline that merely guesses correct classified instances\n",
        "        # are in and incorrectly classified instances are out.\n",
        "        baseline_true_positives = \\\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).mean()\n",
        "        baseline_true_negatives = \\\n",
        "            (y_pred_out.argmax(axis=1) != data.labels_test).mean()\n",
        "        baseline_attack_acc = \\\n",
        "            (baseline_true_positives + baseline_true_negatives) / 2.\n",
        "\n",
        "        baseline_precision = \\\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).sum() / (\n",
        "                (y_pred_in.argmax(axis=1) == data.labels_train).sum() +\n",
        "                (y_pred_out.argmax(axis=1) == data.labels_test).sum()\n",
        "            )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nBaseline True positive rate: {baseline_true_positives:0.4f}, \" +\n",
        "          f\"Baseline true negative rate: {baseline_true_negatives:0.4f}\"\n",
        "        )\n",
        "\n",
        "        # tqdm.write(\n",
        "        #   f\"\\nTrue positive 1 rate: {true_positives_1:0.4f}, \" +\n",
        "        #   f\"true negative 1 rate: {true_negatives_1:0.4f}\"\n",
        "        # )\n",
        "    \n",
        "        # tqdm.write(\n",
        "        #   f\"Shadow Attack Accuracy 1: {attack_acc_1:0.4f}, precision 1: {attack_precision_1:0.4f} \" +\n",
        "        #   f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        # )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 2 rate: {true_positives_2:0.4f}, \" +\n",
        "          f\"true negative 2 rate: {true_negatives_2:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 2: {attack_acc_2:0.4f}, precision 2: {attack_precision_2:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )\n",
        "\n",
        "        # tqdm.write(\n",
        "        #   f\"\\nTrue positive 3 rate: {true_positives_3:0.4f}, \" +\n",
        "        #   f\"true negative 3 rate: {true_negatives_3:0.4f}\"\n",
        "        # )\n",
        "    \n",
        "        # tqdm.write(\n",
        "        #   f\"Shadow Attack Accuracy 3: {attack_acc_3:0.4f}, precision 3: {attack_precision_3:0.4f} \" +\n",
        "        #   f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        # )\n",
        "\n",
        "        # tqdm.write(\n",
        "        #   f\"\\nTrue positive 4 rate: {true_positives_4:0.4f}, \" +\n",
        "        #   f\"true negative 4 rate: {true_negatives_4:0.4f}\"\n",
        "        # )\n",
        "    \n",
        "        # tqdm.write(\n",
        "        #   f\"Shadow Attack Accuracy 4: {attack_acc_4:0.4f}, precision 4: {attack_precision_4:0.4f} \" +\n",
        "        #   f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        # )\n",
        "\n",
        "        # tqdm.write(\n",
        "        #   f\"\\nTrue positive 5 rate: {true_positives_5:0.4f}, \" +\n",
        "        #   f\"true negative 5 rate: {true_negatives_5:0.4f}\"\n",
        "        # )\n",
        "    \n",
        "        # tqdm.write(\n",
        "        #   f\"Shadow Attack Accuracy 5: {attack_acc_5:0.4f}, precision 5: {attack_precision_5:0.4f} \" +\n",
        "        #   f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        # )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  12\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [00:38<00:00,  9.65s/split]\n",
            "training attack models: 100%|██████████| 10/10 [00:46<00:00,  4.65s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.5624\n",
            "  Test Accuracy:  0.4170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:15<00:00,  1.55s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 15.01class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.5624, Baseline true negative rate: 0.5830\n",
            "\n",
            "True positive 2 rate: 0.3993, true negative 2 rate: 0.6000\n",
            "Shadow Attack Accuracy 2: 0.4996, precision 2: 0.4996 (baseline: 0.5727, 0.5742)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  24\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [00:52<00:00, 13.15s/split]\n",
            "training attack models: 100%|██████████| 10/10 [00:53<00:00,  5.38s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.7189\n",
            "  Test Accuracy:  0.4225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:18<00:00,  1.80s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 13.28class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.7189, Baseline true negative rate: 0.5775\n",
            "\n",
            "True positive 2 rate: 0.5028, true negative 2 rate: 0.7000\n",
            "Shadow Attack Accuracy 2: 0.6014, precision 2: 0.6263 (baseline: 0.6482, 0.6298)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  36\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [01:09<00:00, 17.35s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:01<00:00,  6.13s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.8405\n",
            "  Test Accuracy:  0.4140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:20<00:00,  2.04s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 12.32class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.8405, Baseline true negative rate: 0.5860\n",
            "\n",
            "True positive 2 rate: 0.5104, true negative 2 rate: 0.6000\n",
            "Shadow Attack Accuracy 2: 0.5552, precision 2: 0.5606 (baseline: 0.7132, 0.6700)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  48\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [01:24<00:00, 21.07s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:07<00:00,  6.77s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9385\n",
            "  Test Accuracy:  0.4201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:23<00:00,  2.31s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 10.46class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9385, Baseline true negative rate: 0.5799\n",
            "\n",
            "True positive 2 rate: 1.0000, true negative 2 rate: 0.8000\n",
            "Shadow Attack Accuracy 2: 0.9000, precision 2: 0.8333 (baseline: 0.7592, 0.6908)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  60\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [01:38<00:00, 24.56s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:16<00:00,  7.60s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9772\n",
            "  Test Accuracy:  0.4136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:25<00:00,  2.59s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 10.16class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9772, Baseline true negative rate: 0.5864\n",
            "\n",
            "True positive 2 rate: 1.0000, true negative 2 rate: 0.6000\n",
            "Shadow Attack Accuracy 2: 0.8000, precision 2: 0.7143 (baseline: 0.7818, 0.7026)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  72\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [01:56<00:00, 29.14s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:22<00:00,  8.20s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9715\n",
            "  Test Accuracy:  0.4027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:28<00:00,  2.81s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  9.89class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9715, Baseline true negative rate: 0.5973\n",
            "\n",
            "True positive 2 rate: 1.0000, true negative 2 rate: 0.7000\n",
            "Shadow Attack Accuracy 2: 0.8500, precision 2: 0.7692 (baseline: 0.7844, 0.7070)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  84\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [02:11<00:00, 32.89s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:28<00:00,  8.80s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9849\n",
            "  Test Accuracy:  0.4016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:30<00:00,  3.02s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  8.88class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9849, Baseline true negative rate: 0.5984\n",
            "\n",
            "True positive 2 rate: 0.9001, true negative 2 rate: 0.6000\n",
            "Shadow Attack Accuracy 2: 0.7500, precision 2: 0.6923 (baseline: 0.7916, 0.7103)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  96\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [02:28<00:00, 37.01s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:34<00:00,  9.46s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9999\n",
            "  Test Accuracy:  0.4047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:32<00:00,  3.24s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  8.50class/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9999, Baseline true negative rate: 0.5953\n",
            "\n",
            "True positive 2 rate: 1.0000, true negative 2 rate: 0.7000\n",
            "Shadow Attack Accuracy 2: 0.8500, precision 2: 0.7692 (baseline: 0.7976, 0.7119)\n",
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  108\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [02:40<00:00, 40.23s/split]\n",
            "training attack models: 100%|██████████| 10/10 [01:41<00:00, 10.11s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9999\n",
            "  Test Accuracy:  0.4009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:34<00:00,  3.49s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  7.92class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9999, Baseline true negative rate: 0.5991\n",
            "\n",
            "True positive 2 rate: 1.0000, true negative 2 rate: 0.6000\n",
            "Shadow Attack Accuracy 2: 0.8000, precision 2: 0.7143 (baseline: 0.7995, 0.7138)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIJcLETz3T2J",
        "colab_type": "text"
      },
      "source": [
        "Visualization for Written Exercise 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyy4FsGU3oUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "# from matplotlib import cm\n",
        "# from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "# from matplotlib import gridspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r8buMMm3Rwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "61300e56-f9a9-4ac1-e5a9-9b2cc5ecc981"
      },
      "source": [
        "# data to plot\n",
        "n_groups = 9\n",
        "training_accuracy = (0.5624, 0.7189, 0.8405, 0.9385, 0.9772, 0.9715, 0.9849, 0.9999, 0.9999)\n",
        "testing_accuracy = (0.4170, 0.4225, 0.4140, 0.4210, 0.4136, 0.4027, 0.4016, 0.4047, 0.4009)\n",
        "shadow_accuracy = (0.4996, 0.6014, 0.5552, 0.9000, 0.8000, 0.8500, 0.7500, 0.8500, 0.8000)\n",
        "\n",
        "# create plot\n",
        "fig, ax = plt.subplots()\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.2\n",
        "opacity = 0.8\n",
        "\n",
        "rects1 = plt.bar(index, training_accuracy, bar_width,\n",
        "alpha=opacity,\n",
        "color='r',\n",
        "label='Baseline Training')\n",
        "\n",
        "rects2 = plt.bar(index + bar_width, testing_accuracy, bar_width,\n",
        "alpha=opacity,\n",
        "color='b',\n",
        "label='Baseline Testing')\n",
        "\n",
        "rects3 = plt.bar(index + bar_width * 2, shadow_accuracy, bar_width,\n",
        "alpha=opacity,\n",
        "color='g',\n",
        "label='Shadow Attack')\n",
        "\n",
        "plt.xlabel('Epochs used to train baseline')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Baseline & Shadow Attack Accuracy vs. Number of Epochs')\n",
        "plt.xticks(index + bar_width, ('12', '24', '36', '48', '60', '72', '84', '96', '108'))\n",
        "plt.legend(loc = 'lower left')\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = round(rect.get_height(), 2)\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 3, height),\n",
        "                    xytext=(3, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FPBGbLBAnVU",
        "colab_type": "text"
      },
      "source": [
        "Overfitting Ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xs3FNrJ_rBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "037967e5-064b-4fbf-fb1e-96263bb17daa"
      },
      "source": [
        "ratio_of_overfitting = [training_accuracy[i]/testing_accuracy[i] for i in range(len(training_accuracy))]\n",
        "print(np.asarray(ratio_of_overfitting).round(2))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.35 1.7  2.03 2.23 2.36 2.41 2.45 2.47 2.49]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD4mTjJehwkz",
        "colab_type": "text"
      },
      "source": [
        "Written Exercise 5 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZB0E7tUhi6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "26e40c6e-a39a-4140-c99f-e013b2c0d3da"
      },
      "source": [
        "# YOUR IMPLEMENTATION FOR THE SHADOW MODEL ATTACK GOES HERE ###################\n",
        "\n",
        "\n",
        "def synthesize_attack_data(\n",
        "    target_model: hw5_part1_utils.TargetModel,\n",
        "    shadow_data: np.ndarray,\n",
        "    shadow_labels: np.ndarray,\n",
        "    num_shadow_models: int = 4\n",
        "):\n",
        "    \"\"\"Synthesize attack data.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        target_model {TargetModel} -- an instance of the TargetModel class;\n",
        "          behaves as a keras model but additionally has a train_shadow_model\n",
        "          function, which takes a subset of the shadow data and labels and\n",
        "          returns a model with identical architecture and hyperparameters to\n",
        "          the original target model, but that is trained on the given shadow\n",
        "          data.\n",
        "\n",
        "        shadow_data {np.ndarray} -- data available to the attack to train\n",
        "          shadow models. If the arget model's training set is size N x D,\n",
        "          shadow_data is 2N x D.\n",
        "\n",
        "        shadow_labels {np.ndarray} -- the corresponding labels to the\n",
        "          shadow_data, given as a numpy array of 2N integers in the range 0 to\n",
        "          C where C is the number of classes.\n",
        "\n",
        "        num_shadow_models {int} -- the number of shadow models to use when\n",
        "          constructing the attack model's dataset.\n",
        "\n",
        "    Returns: three np.ndarrays; let M = 2N * num_shadow_models\n",
        "\n",
        "        attack_data {np.ndarray} [M, 2C] -- shadow data label probability and\n",
        "           label one-hot\n",
        "\n",
        "        attack_classes {np.ndarray} [M, 1 of {0,1,...,C-1}] -- shadow data\n",
        "           labels\n",
        "\n",
        "        attack_labels {np.ndarray} [M, 1 of {0,1}] -- attack data labels\n",
        "           (training membership)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    C = shadow_labels.max() + 1\n",
        "\n",
        "    attack_data: np.ndarray = None\n",
        "    attack_classes: np.ndarray = None\n",
        "    attack_labels: np.ndarray = None\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    in_data = []\n",
        "    out_data = []\n",
        "    shadow_data_classes = []\n",
        "\n",
        "    for i in tqdm(\n",
        "        range(num_shadow_models),\n",
        "        desc=\"training shadow models\",\n",
        "        unit=\"split\"\n",
        "    ):\n",
        "\n",
        "        split = hw5_part1_utils.DataSplit(shadow_labels, seed=i)\n",
        "\n",
        "        shadow_model = target_model.train_shadow_model(\n",
        "            shadow_data[split.in_idx], shadow_labels[split.in_idx],\n",
        "            # shadow_data[split.out_idx], shadow_labels[split.out_idx]\n",
        "            # validation data\n",
        "        )\n",
        "\n",
        "        in_pred = shadow_model.predict(shadow_data[split.in_idx])\n",
        "        in_onehot = to_categorical(\n",
        "            shadow_labels[split.in_idx], C\n",
        "        )\n",
        "        in_data.append(np.concatenate(\n",
        "            (in_pred, in_onehot),\n",
        "            axis=1)\n",
        "        )\n",
        "\n",
        "        out_pred = shadow_model.predict(shadow_data[split.out_idx])\n",
        "        out_onehot = to_categorical(\n",
        "            shadow_labels[split.out_idx], C\n",
        "        )\n",
        "        out_data.append(np.concatenate(\n",
        "            (out_pred, out_onehot),\n",
        "            axis=1)\n",
        "        )\n",
        "        shadow_data_classes.append(shadow_labels[split.in_idx])\n",
        "        shadow_data_classes.append(shadow_labels[split.out_idx])\n",
        "\n",
        "    in_data = np.concatenate(in_data)\n",
        "    out_data = np.concatenate(out_data)\n",
        "\n",
        "    attack_data = np.concatenate((in_data, out_data))\n",
        "\n",
        "    attack_labels = np.concatenate((\n",
        "        np.ones(len(in_data)),\n",
        "        np.zeros(len(out_data)))\n",
        "    )\n",
        "\n",
        "    attack_classes = np.concatenate(shadow_data_classes)\n",
        "\n",
        "    ###\n",
        "\n",
        "    return attack_data, attack_classes, attack_labels\n",
        "\n",
        "\n",
        "def build_attack_models(\n",
        "    target_model: hw5_part1_utils.TargetModel,\n",
        "    shadow_data: np.ndarray,\n",
        "    shadow_labels: np.ndarray,\n",
        "    num_shadow_models: int = 4,\n",
        "    batch_size=2048,\n",
        "    epochs=32\n",
        "):\n",
        "    \"\"\"Build attacker models.\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        target_model {TargetModel} -- an instance of the TargetModel class;\n",
        "          behaves as a keras model but additionally has a train_shadow_model\n",
        "          function, which takes a subset of the shadow data and labels and\n",
        "          returns a model with identical architecture and hyperparameters to\n",
        "          the original target model, but that is trained on the given shadow\n",
        "          data.\n",
        "\n",
        "        shadow_data {np.ndarray} -- data available to the attack to train\n",
        "          shadow models. If the arget model's training set is size N x D,\n",
        "          shadow_data is 2N x D.\n",
        "\n",
        "        shadow_labels {np.ndarray} -- the corresponding labels to the\n",
        "          shadow_data, given as a numpy array of 2N integers in the range 0 to\n",
        "          C where C is the number of classes.\n",
        "\n",
        "        num_shadow_models {int} -- the number of shadow models to use when\n",
        "          constructing the attack model's dataset.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "        {tuple} -- a tuple of C keras models, where the c^th model predicts the\n",
        "        probability that an instance of class c was a training set member.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    attack_data, attack_classes, attack_labels = \\\n",
        "        synthesize_attack_data(\n",
        "            target_model,\n",
        "            shadow_data,\n",
        "            shadow_labels,\n",
        "            num_shadow_models=4\n",
        "        )\n",
        "\n",
        "    # to return\n",
        "    attack_models: Tuple[Model] = None\n",
        "\n",
        "    C = shadow_labels.max() + 1\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    #Define the attack model architecture.\n",
        "    def get_attack_model_architecture_1():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(128, activation='relu')(attack_x)\n",
        "        attack_y = Dense(64, activation='relu')(attack_y)\n",
        "        attack_y = Dense(32, activation='relu')(attack_y)\n",
        "        attack_y = Dense(10, activation='relu')(attack_y)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "\n",
        "        # Define the attack model architecture.\n",
        "    def get_attack_model_architecture_2():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(4 * C, activation='relu')(attack_x)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "\n",
        "        # Define the attack model architecture.\n",
        "    def get_attack_model_architecture_3():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(20, activation='relu')(attack_x)\n",
        "        attack_y = Dense(20, activation='relu')(attack_y)\n",
        "        attack_y = Dense(20, activation='relu')(attack_y)\n",
        "        attack_y = Dense(20, activation='relu')(attack_y)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "    \n",
        "        # Define the attack model architecture.\n",
        "    def get_attack_model_architecture_4():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(20, activation='relu')(attack_x)\n",
        "        attack_y = Dense(16, activation='relu')(attack_x)\n",
        "        attack_y = Dense(12, activation='relu')(attack_x)\n",
        "        attack_y = Dense(8, activation='relu')(attack_x)\n",
        "        attack_y = Dense(4, activation='relu')(attack_x)\n",
        "        attack_y = Dense(2, activation='relu')(attack_x)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "\n",
        "        # Define the attack model architecture.\n",
        "    def get_attack_model_architecture_5():\n",
        "        attack_x = Input((2 * C,))\n",
        "        attack_y = Dense(48, activation='relu')(attack_x)\n",
        "        attack_y = Dropout(0.2)(attack_y)\n",
        "        attack_y = Dense(48, activation='relu')(attack_y)\n",
        "        attack_y = Dropout(0.2)(attack_y)\n",
        "        attack_y = Dense(32, activation='relu')(attack_y)\n",
        "        attack_y = Dropout(0.2)(attack_y)\n",
        "        attack_y = Dense(16, activation='relu')(attack_y)\n",
        "        attack_y = Dropout(0.2)(attack_y)\n",
        "        attack_y = Dense(10, activation='relu')(attack_y)\n",
        "        attack_y = Dropout(0.2)(attack_y)\n",
        "        attack_y = Dense(1, activation='sigmoid')(attack_y)\n",
        "\n",
        "        attack_model = Model(attack_x, attack_y)\n",
        "\n",
        "        attack_model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return attack_model\n",
        "\n",
        "    # Train the attack model. We have one model per ground truth class.\n",
        "    ret_models_1 = []\n",
        "    ret_models_2 = []\n",
        "    ret_models_3 = []\n",
        "    ret_models_4 = []\n",
        "    ret_models_5 = []\n",
        "    for c in tqdm(range(C), desc=\"training attack models\", unit=\"class\"):\n",
        "        attack_model_1 = get_attack_model_architecture_1()\n",
        "\n",
        "        attack_model_1.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_1.append(attack_model_1)\n",
        "\n",
        "        attack_model_2 = get_attack_model_architecture_2()\n",
        "\n",
        "        attack_model_2.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_2.append(attack_model_2)\n",
        "\n",
        "        attack_model_3 = get_attack_model_architecture_3()\n",
        "\n",
        "        attack_model_3.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_3.append(attack_model_3)\n",
        "\n",
        "        attack_model_4 = get_attack_model_architecture_4()\n",
        "\n",
        "        attack_model_4.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_4.append(attack_model_4)\n",
        "\n",
        "        attack_model_5 = get_attack_model_architecture_5()\n",
        "\n",
        "        attack_model_5.fit(\n",
        "            attack_data[attack_classes == c],\n",
        "            attack_labels[attack_classes == c],\n",
        "            batch_size=batch_size,\n",
        "            verbose=0,\n",
        "            epochs=epochs\n",
        "        )\n",
        "\n",
        "        ret_models_5.append(attack_model_5)\n",
        "\n",
        "    attack_models_1 = tuple(ret_models_1)\n",
        "    attack_models_2 = tuple(ret_models_2)\n",
        "    attack_models_3 = tuple(ret_models_3)\n",
        "    attack_models_4 = tuple(ret_models_4)\n",
        "    attack_models_5 = tuple(ret_models_5)\n",
        "\n",
        "    ###\n",
        "\n",
        "    return attack_models_1, attack_models_2, attack_models_3, attack_models_4, attack_models_5\n",
        "    # return attack_models_2\n",
        "\n",
        "\n",
        "def evaluate_membership(attack_models, y_pred, y):\n",
        "    \"\"\"Evaluate the attacker about the membership inference\n",
        "\n",
        "    Arguments:\n",
        "\n",
        "        attack_model {tuple} -- a tuple of C keras models, where C is the\n",
        "          number of classes.\n",
        "\n",
        "        y_pred {np.ndarray} -- an N x C numpy array with the predictions of the\n",
        "          model on the N instances we are performing the inference attack on.\n",
        "\n",
        "        y {np.ndarray} -- the true labels for each of the instances given as a\n",
        "          numpy array of N integers.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "        {np.ndarray} -- an array of N floats in the range [0,1] representing\n",
        "          the estimated probability that each of the N given instances is a\n",
        "          training set member.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # To return\n",
        "    preds: np.ndarray = None\n",
        "\n",
        "    # SOLUTION\n",
        "    # raise NotImplementedError('You need to implement this.')\n",
        "    attack_in = np.concatenate((y_pred, to_categorical(y)), axis=1)\n",
        "\n",
        "    preds = np.zeros(y.shape)\n",
        "\n",
        "    for c in tqdm(range(len(attack_models)),\n",
        "                  desc=\"evaluating submodels\",\n",
        "                  unit=\"class\"):\n",
        "\n",
        "        preds[y == c] = attack_models[c].predict(attack_in[y == c])[0]\n",
        "\n",
        "    ###\n",
        "\n",
        "    return preds\n",
        "\n",
        "# YOU DO NOT NEED TO MODIFY THE REST OF THIS CODE. ############################\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the dataset.\n",
        "    data = hw5_part1_utils.CIFARData()\n",
        "\n",
        "    # Make a target model for the dataset.\n",
        "    target_model_epochs = [48]\n",
        "    for i in range(len(target_model_epochs)):\n",
        "        target_model = \\\n",
        "            hw5_part1_utils.CIFARModel(\n",
        "                epochs=target_model_epochs[i],\n",
        "                batch_size=2048,\n",
        "                noload=True, # prevents loading an existing pre-trained target\n",
        "                            # model\n",
        "            ).init(\n",
        "                data.train, data.labels_train,\n",
        "                # data.test, data.labels_test # validation data\n",
        "            )\n",
        "        print(\"\\nTarget Model Epochs: \", target_model_epochs[i])\n",
        "        tqdm.write('Building attack model...')\n",
        "        attack_models_1, attack_models_2, attack_models_3, attack_models_4, attack_models_5 = build_attack_models(\n",
        "            target_model,\n",
        "            data.shadow,\n",
        "            data.labels_shadow\n",
        "        )\n",
        "\n",
        "        # tqdm.write('Building attack model...')\n",
        "        # attack_models_2 = build_attack_models(\n",
        "        #     target_model,\n",
        "        #     data.shadow,\n",
        "        #     data.labels_shadow\n",
        "        # )\n",
        "\n",
        "        tqdm.write('Evaluating target model...')\n",
        "        y_pred_in = target_model.predict(data.train)\n",
        "        y_pred_out = target_model.predict(data.test)\n",
        "\n",
        "        tqdm.write('  Train Accuracy: {:.4f}'.format(\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).mean()))\n",
        "        tqdm.write('  Test Accuracy:  {:.4f}'.format(\n",
        "            (y_pred_out.argmax(axis=1) == data.labels_test).mean()))\n",
        "\n",
        "        in_preds_1 = evaluate_membership(\n",
        "            attack_models_1,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_1 = evaluate_membership(\n",
        "            attack_models_1,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        in_preds_2 = evaluate_membership(\n",
        "            attack_models_2,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_2 = evaluate_membership(\n",
        "            attack_models_2,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        in_preds_3 = evaluate_membership(\n",
        "            attack_models_3,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_3 = evaluate_membership(\n",
        "            attack_models_3,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        in_preds_4 = evaluate_membership(\n",
        "            attack_models_4,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_4 = evaluate_membership(\n",
        "            attack_models_4,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        in_preds_5 = evaluate_membership(\n",
        "            attack_models_5,\n",
        "            y_pred_in,\n",
        "            data.labels_train\n",
        "        )\n",
        "        out_preds_5 = evaluate_membership(\n",
        "            attack_models_5,\n",
        "            y_pred_out,\n",
        "            data.labels_test\n",
        "        )\n",
        "\n",
        "        true_positives_1 = (in_preds_1 > 0.5).mean()\n",
        "        true_negatives_1 = (out_preds_1 < 0.5).mean()\n",
        "        attack_acc_1 = (true_positives_1 + true_negatives_1) / 2.\n",
        "\n",
        "        attack_precision_1 = (in_preds_1 > 0.5).sum() / (\n",
        "            (in_preds_1 > 0.5).sum() + (out_preds_1 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "        true_positives_2 = (in_preds_2 > 0.5).mean()\n",
        "        true_negatives_2 = (out_preds_2 < 0.5).mean()\n",
        "        attack_acc_2 = (true_positives_2 + true_negatives_2) / 2.\n",
        "\n",
        "        attack_precision_2 = (in_preds_2 > 0.5).sum() / (\n",
        "            (in_preds_2 > 0.5).sum() + (out_preds_2 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "        true_positives_3 = (in_preds_3 > 0.5).mean()\n",
        "        true_negatives_3 = (out_preds_3 < 0.5).mean()\n",
        "        attack_acc_3 = (true_positives_3 + true_negatives_3) / 2.\n",
        "\n",
        "        attack_precision_3 = (in_preds_3 > 0.5).sum() / (\n",
        "            (in_preds_3 > 0.5).sum() + (out_preds_3 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "        true_positives_4 = (in_preds_4 > 0.5).mean()\n",
        "        true_negatives_4 = (out_preds_4 < 0.5).mean()\n",
        "        attack_acc_4 = (true_positives_4 + true_negatives_4) / 2.\n",
        "\n",
        "        attack_precision_4 = (in_preds_4 > 0.5).sum() / (\n",
        "            (in_preds_4 > 0.5).sum() + (out_preds_4 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "        true_positives_5 = (in_preds_5 > 0.5).mean()\n",
        "        true_negatives_5 = (out_preds_5 < 0.5).mean()\n",
        "        attack_acc_5 = (true_positives_5 + true_negatives_5) / 2.\n",
        "\n",
        "        attack_precision_5 = (in_preds_5 > 0.5).sum() / (\n",
        "            (in_preds_5 > 0.5).sum() + (out_preds_5 > 0.5).sum()\n",
        "        )\n",
        "\n",
        "\n",
        "        wrongs_in = y_pred_in.argmax(axis=1) != data.labels_train\n",
        "        wrongs_out = y_pred_out.argmax(axis=1) != data.labels_test\n",
        "\n",
        "\n",
        "        # Compare to a baseline that merely guesses correct classified instances\n",
        "        # are in and incorrectly classified instances are out.\n",
        "        baseline_true_positives = \\\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).mean()\n",
        "        baseline_true_negatives = \\\n",
        "            (y_pred_out.argmax(axis=1) != data.labels_test).mean()\n",
        "        baseline_attack_acc = \\\n",
        "            (baseline_true_positives + baseline_true_negatives) / 2.\n",
        "\n",
        "        baseline_precision = \\\n",
        "            (y_pred_in.argmax(axis=1) == data.labels_train).sum() / (\n",
        "                (y_pred_in.argmax(axis=1) == data.labels_train).sum() +\n",
        "                (y_pred_out.argmax(axis=1) == data.labels_test).sum()\n",
        "            )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nBaseline True positive rate: {baseline_true_positives:0.4f}, \" +\n",
        "          f\"Baseline true negative rate: {baseline_true_negatives:0.4f}\"\n",
        "        )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 1 rate: {true_positives_1:0.4f}, \" +\n",
        "          f\"true negative 1 rate: {true_negatives_1:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 1: {attack_acc_1:0.4f}, precision 1: {attack_precision_1:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 2 rate: {true_positives_2:0.4f}, \" +\n",
        "          f\"true negative 2 rate: {true_negatives_2:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 2: {attack_acc_2:0.4f}, precision 2: {attack_precision_2:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 3 rate: {true_positives_3:0.4f}, \" +\n",
        "          f\"true negative 3 rate: {true_negatives_3:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 3: {attack_acc_3:0.4f}, precision 3: {attack_precision_3:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 4 rate: {true_positives_4:0.4f}, \" +\n",
        "          f\"true negative 4 rate: {true_negatives_4:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 4: {attack_acc_4:0.4f}, precision 4: {attack_precision_4:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )\n",
        "\n",
        "        tqdm.write(\n",
        "          f\"\\nTrue positive 5 rate: {true_positives_5:0.4f}, \" +\n",
        "          f\"true negative 5 rate: {true_negatives_5:0.4f}\"\n",
        "        )\n",
        "    \n",
        "        tqdm.write(\n",
        "          f\"Shadow Attack Accuracy 5: {attack_acc_5:0.4f}, precision 5: {attack_precision_5:0.4f} \" +\n",
        "          f\"(baseline: {baseline_attack_acc:0.4f}, {baseline_precision:0.4f})\"\n",
        "        )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining shadow models:   0%|          | 0/4 [00:00<?, ?split/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target Model Epochs:  48\n",
            "Building attack model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training shadow models: 100%|██████████| 4/4 [01:06<00:00, 16.67s/split]\n",
            "training attack models: 100%|██████████| 10/10 [05:14<00:00, 31.44s/class]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluating target model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\revaluating submodels:   0%|          | 0/10 [00:00<?, ?class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Train Accuracy: 0.9359\n",
            "  Test Accuracy:  0.4078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating submodels: 100%|██████████| 10/10 [00:25<00:00,  2.59s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  9.90class/s]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:25<00:00,  2.58s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 10.40class/s]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:25<00:00,  2.59s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  9.54class/s]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:25<00:00,  2.55s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:00<00:00, 10.32class/s]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:26<00:00,  2.60s/class]\n",
            "evaluating submodels: 100%|██████████| 10/10 [00:01<00:00,  8.98class/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline True positive rate: 0.9359, Baseline true negative rate: 0.5922\n",
            "\n",
            "True positive 1 rate: 0.9001, true negative 1 rate: 0.7000\n",
            "Shadow Attack Accuracy 1: 0.8000, precision 1: 0.7500 (baseline: 0.7640, 0.6965)\n",
            "\n",
            "True positive 2 rate: 0.8064, true negative 2 rate: 0.7000\n",
            "Shadow Attack Accuracy 2: 0.7532, precision 2: 0.7289 (baseline: 0.7640, 0.6965)\n",
            "\n",
            "True positive 3 rate: 1.0000, true negative 3 rate: 0.7000\n",
            "Shadow Attack Accuracy 3: 0.8500, precision 3: 0.7692 (baseline: 0.7640, 0.6965)\n",
            "\n",
            "True positive 4 rate: 0.9026, true negative 4 rate: 0.5000\n",
            "Shadow Attack Accuracy 4: 0.7013, precision 4: 0.6435 (baseline: 0.7640, 0.6965)\n",
            "\n",
            "True positive 5 rate: 1.0000, true negative 5 rate: 0.7000\n",
            "Shadow Attack Accuracy 5: 0.8500, precision 5: 0.7692 (baseline: 0.7640, 0.6965)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-1cxlk987ru",
        "colab_type": "text"
      },
      "source": [
        "Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YNRjD2pE1o2",
        "colab_type": "code",
        "outputId": "cb021bcf-a767-4934-f28e-8027a51a2790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install gensim json\n",
        "!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
        "!gunzip GoogleNews-vectors-negative300.bin.gz\n",
        "!mv GoogleNews-vectors-negative300.bin data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for json\u001b[0m\n",
            "--2020-05-15 06:40:39--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.38.14\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.38.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.9MB/s    in 96s     \n",
            "\n",
            "2020-05-15 06:42:16 (16.3 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnXPjtd0E1up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "import gensim.models\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import json\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWMppznZQmUf",
        "colab_type": "text"
      },
      "source": [
        "Written Exercise 17 and 18 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMg1N8omErBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "5100e0c4-711e-4867-ac35-d58273878c57"
      },
      "source": [
        "class WordEmbeddingDebiaser:\n",
        "\n",
        "    def __init__(self,\n",
        "                 embedding_file_path,\n",
        "                 definitional_file_path='./data/definitional_pairs.json',\n",
        "                 equalize_file_path='./data/equalize_pairs.json',\n",
        "                 gender_specific_file_path='./data/gender_specific_full.json'):\n",
        "\n",
        "        self.model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "            embedding_file_path, binary=True)\n",
        "\n",
        "        # collect first 300000 words\n",
        "        self.words = sorted([w for w in self.model.vocab],\n",
        "                            key=lambda w: self.model.vocab[w].index)[:300000]\n",
        "\n",
        "        # all vectors in an array (same order as self.words)\n",
        "        self.vecs = np.array([self.model[w] for w in self.words])\n",
        "        tqdm.write('vectors loaded')\n",
        "        # should take 2-5 min depending on your machine\n",
        "\n",
        "        self.n, self.d = self.vecs.shape\n",
        "\n",
        "        # word to index dictionary\n",
        "        self.w2i = {w: i for i, w in enumerate(self.words)}\n",
        "\n",
        "        # Some relevant words sets required for debiasing\n",
        "        with open(definitional_file_path, \"r\") as f:\n",
        "            self.definition_pairs = json.load(f)\n",
        "\n",
        "        with open(equalize_file_path, \"r\") as f:\n",
        "            self.equalize_pairs = json.load(f)\n",
        "\n",
        "        with open(gender_specific_file_path, \"r\") as f:\n",
        "            self.gender_specific_words = json.load(f)\n",
        "        self._normalize()\n",
        "\n",
        "    # Some potentially helpful functions, you don't have to use/implement them.\n",
        "    def _normalize(self):\n",
        "        \"\"\"\n",
        "        normalize self.vecs\n",
        "        \"\"\"\n",
        "        self.vecs /= np.linalg.norm(self.vecs, axis=1)[:, np.newaxis]\n",
        "\n",
        "    def _drop(self, u, v):\n",
        "        \"\"\"\n",
        "        remove a direction v from u\n",
        "        \"\"\"\n",
        "        return u - v * u.dot(v) / v.dot(v)\n",
        "\n",
        "    def w2v(self, word):\n",
        "        \"\"\"\n",
        "        for a word, return its corresponding vector\n",
        "        \"\"\"\n",
        "        return self.vecs[self.w2i[word]]\n",
        "\n",
        "    def debias(self):\n",
        "        self.gender_direction = self.identify_gender_subspace()\n",
        "        self.neutralize()\n",
        "        self.equalize()\n",
        "\n",
        "    def identify_gender_subspace(self):\n",
        "        \"\"\"Using self.definitional_pairs to identify a gender axis (1 dimensional).\n",
        "\n",
        "          Output: a gender direction using definitonal pairs\n",
        "\n",
        "        ****Note****\n",
        "\n",
        "         no other unimported packages listed above are allowed, please use\n",
        "         numpy.linalg.svd for PCA\n",
        "\n",
        "        \"\"\"\n",
        "        matrix = []\n",
        "        for a, b in self.definition_pairs:\n",
        "            center = (self.w2v(a) + self.w2v(b)) / 2\n",
        "            matrix.append(self.w2v(a) - center)\n",
        "            matrix.append(self.w2v(b) - center)\n",
        "        matrix = np.array(matrix)\n",
        "        # pca = PCA(n_components=10)\n",
        "        # pca.fit(matrix)\n",
        "        # gender_direction = pca.components_[0]\n",
        "        u, s, v = np.linalg.svd(matrix)\n",
        "        gender_direction = v[0, :]\n",
        "\n",
        "        return gender_direction\n",
        "\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    def neutralize(self):\n",
        "        \"\"\"Performing the neutralizing step: projecting all gender neurtal words away\n",
        "        from the gender direction\n",
        "\n",
        "        No output, please adjust self.vecs\n",
        "\n",
        "        \"\"\"\n",
        "        specific_set = set(self.gender_specific_words)\n",
        "        for i, w in enumerate(self.words):\n",
        "            if w not in specific_set:\n",
        "                self.vecs[i] = self._drop(self.vecs[i], self.gender_direction)\n",
        "        self._normalize()\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    def equalize(self):\n",
        "        \"\"\"Performing the equalizing step: make sure all equalized pairs are\n",
        "        equaldistant to the gender direction.\n",
        "\n",
        "        No output, please adapt self.vecs\n",
        "\n",
        "        \"\"\"\n",
        "        for (a, b) in self.equalize_pairs:\n",
        "            if (a in self.w2i and b in self.w2i):\n",
        "                y = self._drop((self.w2v(a) + self.w2v(b)) / 2,\n",
        "                               self.gender_direction)\n",
        "                z = np.sqrt(1 - np.linalg.norm(y)**2)\n",
        "                if (self.w2v(a) - self.w2v(b)).dot(self.gender_direction) < 0:\n",
        "                    z = -z\n",
        "                self.vecs[self.w2i[a]] = z * self.gender_direction + y\n",
        "                self.vecs[self.w2i[b]] = -z * self.gender_direction + y\n",
        "        self._normalize()\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "        # pass\n",
        "    def compute_analogy(self, w3, w1='woman', w2='man'):\n",
        "        \"\"\"input: w3, w1, w2, satifying the analogy w1: w2 :: w3 : w4\n",
        "\n",
        "        output: w4(a word string) which is the solution to the analogy (w4 is\n",
        "          constrained to be different from w1, w2 and w3)\n",
        "\n",
        "        \"\"\"\n",
        "        diff = self.w2v(w2) - self.w2v(w1)\n",
        "        vec = diff / np.linalg.norm(diff) + self.w2v(w3)\n",
        "        vec = vec / np.linalg.norm(vec)\n",
        "        if w3 == self.words[np.argsort(vec.dot(self.vecs.T))[-1]]:\n",
        "            return self.words[np.argsort(vec.dot(self.vecs.T))[-2]]\n",
        "        return self.words[np.argmax(vec.dot(self.vecs.T))]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Original Embedding\n",
        "\n",
        "    we = WordEmbeddingDebiaser('./data/GoogleNews-vectors-negative300.bin')\n",
        "\n",
        "    print('=' * 50)\n",
        "    print('Original Embeddings')\n",
        "    # she-he analogy evaluation\n",
        "    w3s1 = [\n",
        "        'her', 'herself', 'spokeswoman', 'daughter', 'mother', 'niece',\n",
        "        'chairwoman', 'Mary', 'sister', 'actress'\n",
        "    ]\n",
        "    w3s2 = [\n",
        "        'nurse', 'dancer', 'feminist', 'baking', 'volleyball', 'softball',\n",
        "        'salon', 'blond', 'cute', 'beautiful'\n",
        "    ]\n",
        "\n",
        "    w4s1 = [we.compute_analogy(w3) for w3 in w3s1]\n",
        "    w4s2 = [we.compute_analogy(w3) for w3 in w3s2]\n",
        "\n",
        "    print('Appropriate Analogies')\n",
        "    for w3, w4 in zip(w3s1, w4s1):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    print('Potentially Biased Analogies')\n",
        "    for w3, w4 in zip(w3s2, w4s2):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    we.debias()\n",
        "\n",
        "    print('=' * 50)\n",
        "    print('Debiased  Embeddings')\n",
        "    # she-he analogy evaluation\n",
        "    w4s1 = [we.compute_analogy(w3) for w3 in w3s1]\n",
        "    w4s2 = [we.compute_analogy(w3) for w3 in w3s2]\n",
        "\n",
        "    print('Appropriate Analogies')\n",
        "    for w3, w4 in zip(w3s1, w4s1):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    print('Potentially Biased Analogies')\n",
        "    for w3, w4 in zip(w3s2, w4s2):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "vectors loaded\n",
            "==================================================\n",
            "Original Embeddings\n",
            "Appropriate Analogies\n",
            "'woman' is to 'her' as 'man' is to 'his'\n",
            "'woman' is to 'herself' as 'man' is to 'himself'\n",
            "'woman' is to 'spokeswoman' as 'man' is to 'spokesman'\n",
            "'woman' is to 'daughter' as 'man' is to 'son'\n",
            "'woman' is to 'mother' as 'man' is to 'father'\n",
            "'woman' is to 'niece' as 'man' is to 'nephew'\n",
            "'woman' is to 'chairwoman' as 'man' is to 'chairman'\n",
            "'woman' is to 'Mary' as 'man' is to 'Paul'\n",
            "'woman' is to 'sister' as 'man' is to 'brother'\n",
            "'woman' is to 'actress' as 'man' is to 'actor'\n",
            "Potentially Biased Analogies\n",
            "'woman' is to 'nurse' as 'man' is to 'medic'\n",
            "'woman' is to 'dancer' as 'man' is to 'magician'\n",
            "'woman' is to 'feminist' as 'man' is to 'anarchist'\n",
            "'woman' is to 'baking' as 'man' is to 'roasting'\n",
            "'woman' is to 'volleyball' as 'man' is to 'football'\n",
            "'woman' is to 'softball' as 'man' is to 'baseball'\n",
            "'woman' is to 'salon' as 'man' is to 'barber_shop'\n",
            "'woman' is to 'blond' as 'man' is to 'burly'\n",
            "'woman' is to 'cute' as 'man' is to 'goofy'\n",
            "'woman' is to 'beautiful' as 'man' is to 'magnificent'\n",
            "==================================================\n",
            "Debiased  Embeddings\n",
            "Appropriate Analogies\n",
            "'woman' is to 'her' as 'man' is to 'his'\n",
            "'woman' is to 'herself' as 'man' is to 'himself'\n",
            "'woman' is to 'spokeswoman' as 'man' is to 'spokesman'\n",
            "'woman' is to 'daughter' as 'man' is to 'son'\n",
            "'woman' is to 'mother' as 'man' is to 'father'\n",
            "'woman' is to 'niece' as 'man' is to 'nephew'\n",
            "'woman' is to 'chairwoman' as 'man' is to 'chairman'\n",
            "'woman' is to 'Mary' as 'man' is to 'Father'\n",
            "'woman' is to 'sister' as 'man' is to 'brother'\n",
            "'woman' is to 'actress' as 'man' is to 'actor'\n",
            "Potentially Biased Analogies\n",
            "'woman' is to 'nurse' as 'man' is to 'gentleman'\n",
            "'woman' is to 'dancer' as 'man' is to 'dancers'\n",
            "'woman' is to 'feminist' as 'man' is to 'feminists'\n",
            "'woman' is to 'baking' as 'man' is to 'cooking'\n",
            "'woman' is to 'volleyball' as 'man' is to 'softball'\n",
            "'woman' is to 'softball' as 'man' is to 'Softball'\n",
            "'woman' is to 'salon' as 'man' is to 'hair_salon'\n",
            "'woman' is to 'blond' as 'man' is to 'blonde'\n",
            "'woman' is to 'cute' as 'man' is to 'fella'\n",
            "'woman' is to 'beautiful' as 'man' is to 'gorgeous'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRxMtUTuYJWL",
        "colab_type": "text"
      },
      "source": [
        "Written Exercise 19 Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwLDQPkul31K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "44e71c6b-e888-4f07-ad82-7454879a1da7"
      },
      "source": [
        "class WordEmbeddingDebiaser:\n",
        "\n",
        "    def __init__(self,\n",
        "                 embedding_file_path,\n",
        "                 definitional_file_path='./data/definitional_pairs.json',\n",
        "                 equalize_file_path='./data/equalize_pairs.json',\n",
        "                 gender_specific_file_path='./data/gender_specific_full.json',\n",
        "                 profession_specific_file_path = './data/profession_words.json'):\n",
        "\n",
        "        self.model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "            embedding_file_path, binary=True)\n",
        "\n",
        "        # collect first 300000 words\n",
        "        self.words = sorted([w for w in self.model.vocab],\n",
        "                            key=lambda w: self.model.vocab[w].index)[:300000]\n",
        "\n",
        "        # all vectors in an array (same order as self.words)\n",
        "        self.vecs = np.array([self.model[w] for w in self.words])\n",
        "        self.vecs_copy = self.vecs.copy()\n",
        "        tqdm.write('vectors loaded')\n",
        "        # should take 2-5 min depending on your machine\n",
        "\n",
        "        self.n, self.d = self.vecs.shape\n",
        "\n",
        "        # word to index dictionary\n",
        "        self.w2i = {w: i for i, w in enumerate(self.words)}\n",
        "\n",
        "        # Some relevant words sets required for debiasing\n",
        "        with open(definitional_file_path, \"r\") as f:\n",
        "            self.definition_pairs = json.load(f)\n",
        "\n",
        "        with open(equalize_file_path, \"r\") as f:\n",
        "            self.equalize_pairs = json.load(f)\n",
        "\n",
        "        with open(gender_specific_file_path, \"r\") as f:\n",
        "            self.gender_specific_words = json.load(f)\n",
        "\n",
        "        with open(profession_specific_file_path, \"r\") as f:\n",
        "            self.profession_specific_words = json.load(f)\n",
        "        self._normalize()\n",
        "\n",
        "    # Some potentially helpful functions, you don't have to use/implement them.\n",
        "    def _normalize(self):\n",
        "        \"\"\"\n",
        "        normalize self.vecs\n",
        "        \"\"\"\n",
        "        self.vecs /= np.linalg.norm(self.vecs, axis=1)[:, np.newaxis]\n",
        "\n",
        "    def _drop(self, u, v):\n",
        "        \"\"\"\n",
        "        remove a direction v from u\n",
        "        \"\"\"\n",
        "        return u - v * u.dot(v) / v.dot(v)\n",
        "\n",
        "    def project(self, u, v):\n",
        "        \"\"\"\n",
        "        calculate the bias by projecting words onto gender direction\n",
        "        \"\"\"\n",
        "        vec = v * u.dot(v) / v.dot(v)\n",
        "        return vec\n",
        "\n",
        "\n",
        "    def w2v(self, word):\n",
        "        \"\"\"\n",
        "        for a word, return its corresponding vector\n",
        "        \"\"\"\n",
        "        return self.vecs[self.w2i[word]]\n",
        "\n",
        "    def debias(self):\n",
        "        self.gender_direction = self.identify_gender_subspace()\n",
        "        before_debias_avg, _ = self.avg_bias_calc()\n",
        "        self.neutralize()\n",
        "        self.equalize()\n",
        "        after_debias_avg, after_debias_dict = self.avg_bias_calc()\n",
        "        return before_debias_avg, after_debias_avg, after_debias_dict\n",
        "        # print('Average Bias Before: {}'.format(before_debias_avg))\n",
        "        # print('Average Bias After: {}'.format(after_debias_avg))\n",
        "\n",
        "    def identify_gender_subspace(self):\n",
        "        \"\"\"Using self.definitional_pairs to identify a gender axis (1 dimensional).\n",
        "\n",
        "          Output: a gender direction using definitonal pairs\n",
        "\n",
        "        ****Note****\n",
        "\n",
        "         no other unimported packages listed above are allowed, please use\n",
        "         numpy.linalg.svd for PCA\n",
        "\n",
        "        \"\"\"\n",
        "        matrix = []\n",
        "        for a, b in self.definition_pairs:\n",
        "            center = (self.w2v(a) + self.w2v(b)) / 2\n",
        "            matrix.append(self.w2v(a) - center)\n",
        "            matrix.append(self.w2v(b) - center)\n",
        "        matrix = np.array(matrix)\n",
        "        # pca = PCA(n_components=10)\n",
        "        # pca.fit(matrix)\n",
        "        # gender_direction = pca.components_[0]\n",
        "        u, s, v = np.linalg.svd(matrix)\n",
        "        gender_direction = v[0, :]\n",
        "\n",
        "        return gender_direction\n",
        "\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    def avg_bias_calc(self):\n",
        "        '''Calculate the avg bias of a set of words on the gender space'''\n",
        "        total_count = 0\n",
        "        bias = 0\n",
        "        bias_dict = {}\n",
        "        for word in self.profession_specific_words:\n",
        "            if word in self.words:\n",
        "                word_vector = self.w2v(word)\n",
        "                word_project = self.project(word_vector, self.gender_direction)\n",
        "                word_bias = np.sum(np.absolute(word_project))\n",
        "                bias_dict[word] = word_bias\n",
        "                bias += word_bias\n",
        "                total_count += 1\n",
        "        avg_bias = bias/total_count\n",
        "        bias_dict = {k: bias_dict[k] for k in sorted(bias_dict, key=bias_dict.get, reverse=True)}\n",
        "        return avg_bias, bias_dict\n",
        "\n",
        "    def neutralize(self):\n",
        "        \"\"\"Performing the neutralizing step: projecting all gender neurtal words away\n",
        "        from the gender direction\n",
        "\n",
        "        No output, please adjust self.vecs\n",
        "\n",
        "        \"\"\"\n",
        "        specific_set = set(self.gender_specific_words)\n",
        "        for i, w in enumerate(self.words):\n",
        "            if w not in specific_set:\n",
        "                self.vecs[i] = self._drop(self.vecs[i], self.gender_direction)\n",
        "        self._normalize()\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "\n",
        "    def equalize(self):\n",
        "        \"\"\"Performing the equalizing step: make sure all equalized pairs are\n",
        "        equaldistant to the gender direction.\n",
        "\n",
        "        No output, please adapt self.vecs\n",
        "\n",
        "        \"\"\"\n",
        "        for (a, b) in self.equalize_pairs:\n",
        "            if (a in self.w2i and b in self.w2i):\n",
        "                y = self._drop((self.w2v(a) + self.w2v(b)) / 2,\n",
        "                               self.gender_direction)\n",
        "                z = np.sqrt(1 - np.linalg.norm(y)**2)\n",
        "                if (self.w2v(a) - self.w2v(b)).dot(self.gender_direction) < 0:\n",
        "                    z = -z\n",
        "                self.vecs[self.w2i[a]] = z * self.gender_direction + y\n",
        "                self.vecs[self.w2i[b]] = -z * self.gender_direction + y\n",
        "        self._normalize()\n",
        "        # raise NotImplementedError('You need to implement this.')\n",
        "        # pass\n",
        "    def compute_analogy(self, w3, w1='woman', w2='man'):\n",
        "        \"\"\"input: w3, w1, w2, satifying the analogy w1: w2 :: w3 : w4\n",
        "\n",
        "        output: w4(a word string) which is the solution to the analogy (w4 is\n",
        "          constrained to be different from w1, w2 and w3)\n",
        "\n",
        "        \"\"\"\n",
        "        diff = self.w2v(w2) - self.w2v(w1)\n",
        "        vec = diff / np.linalg.norm(diff) + self.w2v(w3)\n",
        "        vec = vec / np.linalg.norm(vec)\n",
        "        if w3 == self.words[np.argsort(vec.dot(self.vecs.T))[-1]]:\n",
        "            return self.words[np.argsort(vec.dot(self.vecs.T))[-2]]\n",
        "        return self.words[np.argmax(vec.dot(self.vecs.T))]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Original Embedding\n",
        "\n",
        "    we = WordEmbeddingDebiaser('./data/GoogleNews-vectors-negative300.bin')\n",
        "\n",
        "    print('=' * 50)\n",
        "    print('Original Embeddings')\n",
        "    # she-he analogy evaluation\n",
        "    w3s1 = [\n",
        "        'her', 'herself', 'spokeswoman', 'daughter', 'mother', 'niece',\n",
        "        'chairwoman', 'Mary', 'sister', 'actress'\n",
        "    ]\n",
        "    w3s2 = [\n",
        "        'nurse', 'dancer', 'feminist', 'baking', 'volleyball', 'softball',\n",
        "        'salon', 'blond', 'cute', 'beautiful'\n",
        "    ]\n",
        "\n",
        "    w4s1 = [we.compute_analogy(w3) for w3 in w3s1]\n",
        "    w4s2 = [we.compute_analogy(w3) for w3 in w3s2]\n",
        "\n",
        "    print('Appropriate Analogies')\n",
        "    for w3, w4 in zip(w3s1, w4s1):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    print('Potentially Biased Analogies')\n",
        "    for w3, w4 in zip(w3s2, w4s2):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    before_debias_avg, after_debias_avg, after_debias_dict = we.debias()\n",
        "\n",
        "    print('=' * 50)\n",
        "    print('Debiased  Embeddings')\n",
        "    # she-he analogy evaluation\n",
        "    w4s1 = [we.compute_analogy(w3) for w3 in w3s1]\n",
        "    w4s2 = [we.compute_analogy(w3) for w3 in w3s2]\n",
        "\n",
        "    print('Appropriate Analogies')\n",
        "    for w3, w4 in zip(w3s1, w4s1):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "\n",
        "    print('Potentially Biased Analogies')\n",
        "    for w3, w4 in zip(w3s2, w4s2):\n",
        "        print(\"'woman' is to '%s' as 'man' is to '%s'\" % (w3, w4))\n",
        "    \n",
        "    print('Average Bias Before: {}'.format(before_debias_avg))\n",
        "    print('Average Bias After: {}'.format(after_debias_avg))\n",
        "    print('Debiased Bias Dictionary: {}'.format(after_debias_dict))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "vectors loaded\n",
            "==================================================\n",
            "Original Embeddings\n",
            "Appropriate Analogies\n",
            "'woman' is to 'her' as 'man' is to 'his'\n",
            "'woman' is to 'herself' as 'man' is to 'himself'\n",
            "'woman' is to 'spokeswoman' as 'man' is to 'spokesman'\n",
            "'woman' is to 'daughter' as 'man' is to 'son'\n",
            "'woman' is to 'mother' as 'man' is to 'father'\n",
            "'woman' is to 'niece' as 'man' is to 'nephew'\n",
            "'woman' is to 'chairwoman' as 'man' is to 'chairman'\n",
            "'woman' is to 'Mary' as 'man' is to 'Paul'\n",
            "'woman' is to 'sister' as 'man' is to 'brother'\n",
            "'woman' is to 'actress' as 'man' is to 'actor'\n",
            "Potentially Biased Analogies\n",
            "'woman' is to 'nurse' as 'man' is to 'medic'\n",
            "'woman' is to 'dancer' as 'man' is to 'magician'\n",
            "'woman' is to 'feminist' as 'man' is to 'anarchist'\n",
            "'woman' is to 'baking' as 'man' is to 'roasting'\n",
            "'woman' is to 'volleyball' as 'man' is to 'football'\n",
            "'woman' is to 'softball' as 'man' is to 'baseball'\n",
            "'woman' is to 'salon' as 'man' is to 'barber_shop'\n",
            "'woman' is to 'blond' as 'man' is to 'burly'\n",
            "'woman' is to 'cute' as 'man' is to 'goofy'\n",
            "'woman' is to 'beautiful' as 'man' is to 'magnificent'\n",
            "==================================================\n",
            "Debiased  Embeddings\n",
            "Appropriate Analogies\n",
            "'woman' is to 'her' as 'man' is to 'his'\n",
            "'woman' is to 'herself' as 'man' is to 'himself'\n",
            "'woman' is to 'spokeswoman' as 'man' is to 'spokesman'\n",
            "'woman' is to 'daughter' as 'man' is to 'son'\n",
            "'woman' is to 'mother' as 'man' is to 'father'\n",
            "'woman' is to 'niece' as 'man' is to 'nephew'\n",
            "'woman' is to 'chairwoman' as 'man' is to 'chairman'\n",
            "'woman' is to 'Mary' as 'man' is to 'Father'\n",
            "'woman' is to 'sister' as 'man' is to 'brother'\n",
            "'woman' is to 'actress' as 'man' is to 'actor'\n",
            "Potentially Biased Analogies\n",
            "'woman' is to 'nurse' as 'man' is to 'gentleman'\n",
            "'woman' is to 'dancer' as 'man' is to 'dancers'\n",
            "'woman' is to 'feminist' as 'man' is to 'feminists'\n",
            "'woman' is to 'baking' as 'man' is to 'cooking'\n",
            "'woman' is to 'volleyball' as 'man' is to 'softball'\n",
            "'woman' is to 'softball' as 'man' is to 'Softball'\n",
            "'woman' is to 'salon' as 'man' is to 'hair_salon'\n",
            "'woman' is to 'blond' as 'man' is to 'blonde'\n",
            "'woman' is to 'cute' as 'man' is to 'fella'\n",
            "'woman' is to 'beautiful' as 'man' is to 'gorgeous'\n",
            "Average Bias Before: 1.0790870004472708\n",
            "Average Bias After: 0.20575213891194605\n",
            "Debiased Bias Dictionary: {'businessman': 5.807125, 'businesswoman': 5.8071246, 'congressman': 5.736718, 'nun': 5.7034845, 'actress': 5.077461, 'housewife': 5.072379, 'dad': 4.89569, 'councilman': 4.7973695, 'waitress': 3.9749532, 'socialite': 3.7324076, 'maid': 3.6469352, 'ballerina': 3.493219, 'statesman': 2.979043, 'salesman': 2.1058817, 'handyman': 1.4308797, 'monk': 1.0953407, 'teenager': 0.48463893, 'registered_nurse': 5.971503e-07, 'librarian': 4.9927297e-07, 'paralegal': 4.5945893e-07, 'carpenter': 4.5877323e-07, 'clerk': 4.2527074e-07, 'jeweler': 4.0686922e-07, 'guidance_counselor': 3.6678694e-07, 'parishioner': 3.4035799e-07, 'gangster': 3.288502e-07, 'skipper': 3.2048754e-07, 'stylist': 3.1319763e-07, 'assistant_professor': 3.0056827e-07, 'fighter_pilot': 2.976426e-07, 'broadcaster': 2.969599e-07, 'swimmer': 2.8476944e-07, 'cameraman': 2.7335915e-07, 'nurse': 2.6710546e-07, 'lieutenant': 2.6279002e-07, 'custodian': 2.627291e-07, 'gardener': 2.62662e-07, 'chaplain': 2.564875e-07, 'publicist': 2.561462e-07, 'policeman': 2.5536605e-07, 'understudy': 2.5531727e-07, 'student': 2.447847e-07, 'hairdresser': 2.4220031e-07, 'geologist': 2.4020108e-07, 'choreographer': 2.396281e-07, 'architect': 2.3938432e-07, 'instructor': 2.3634888e-07, 'cinematographer': 2.3239917e-07, 'artist': 2.2971729e-07, 'pharmacist': 2.2830318e-07, 'pundit': 2.2303688e-07, 'cartoonist': 2.2128145e-07, 'commentator': 2.1903841e-07, 'vocalist': 2.1362584e-07, 'sportsman': 2.1172414e-07, 'fashion_designer': 2.085729e-07, 'interior_designer': 2.0572641e-07, 'psychiatrist': 2.0571423e-07, 'proprietor': 2.0148414e-07, 'preacher': 1.9997253e-07, 'financier': 1.9982623e-07, 'athlete': 1.9626661e-07, 'wrestler': 1.9392604e-07, 'maestro': 1.9281671e-07, 'astronomer': 1.9251195e-07, 'environmentalist': 1.9129288e-07, 'dancer': 1.8985443e-07, 'graphic_designer': 1.8904984e-07, 'surveyor': 1.882209e-07, 'violinist': 1.8807461e-07, 'steward': 1.8718166e-07, 'researcher': 1.8631918e-07, 'plumber': 1.8607538e-07, 'industrialist': 1.8588034e-07, 'colonel': 1.852891e-07, 'curator': 1.8485633e-07, 'detective': 1.828571e-07, 'bookkeeper': 1.8076034e-07, 'sociologist': 1.7701785e-07, 'trumpeter': 1.7700566e-07, 'neurosurgeon': 1.7315347e-07, 'protege': 1.7309253e-07, 'provost': 1.7112376e-07, 'nanny': 1.6855539e-07, 'employee': 1.6310852e-07, 'professor_emeritus': 1.6286472e-07, 'aide': 1.6023156e-07, 'receptionist': 1.5981709e-07, 'patrolman': 1.5974396e-07, 'deputy': 1.5818358e-07, 'housekeeper': 1.564891e-07, 'marksman': 1.4940645e-07, 'president': 1.4926015e-07, 'adventurer': 1.4706586e-07, 'manager': 1.4690738e-07, 'bodyguard': 1.4589558e-07, 'columnist': 1.4555425e-07, 'ambassador': 1.4540683e-07, 'undersecretary': 1.4492035e-07, 'critic': 1.4462776e-07, 'promoter': 1.4194586e-07, 'prosecutor': 1.3815463e-07, 'footballer': 1.3794738e-07, 'chancellor': 1.3724949e-07, 'tycoon': 1.3643577e-07, 'constable': 1.3604568e-07, 'pathologist': 1.3596949e-07, 'counselor': 1.3550931e-07, 'coach': 1.3455843e-07, 'headmaster': 1.3431463e-07, 'programmer': 1.3426587e-07, 'epidemiologist': 1.3297368e-07, 'inspector': 1.3272987e-07, 'medic': 1.3263235e-07, 'drummer': 1.324373e-07, 'historian': 1.315352e-07, 'servant': 1.3097444e-07, 'laborer': 1.2973177e-07, 'treasurer': 1.2931653e-07, 'realtor': 1.27171e-07, 'chemist': 1.2711006e-07, 'vice_chancellor': 1.2697596e-07, 'warrior': 1.259032e-07, 'playwright': 1.2561063e-07, 'homemaker': 1.2556185e-07, 'superintendent': 1.2531807e-07, 'screenwriter': 1.2523273e-07, 'minister': 1.2263615e-07, 'illustrator': 1.2209978e-07, 'firebrand': 1.2002738e-07, 'anthropologist': 1.1946663e-07, 'economics_professor': 1.1946663e-07, 'administrator': 1.18491386e-07, 'evangelist': 1.1810131e-07, 'cellist': 1.1729673e-07, 'banker': 1.1693101e-07, 'entrepreneur': 1.1381026e-07, 'stockbroker': 1.1378587e-07, 'jurist': 1.1371273e-07, 'adjunct_professor': 1.1366397e-07, 'solicitor': 1.1205482e-07, 'boxer': 1.1137216e-07, 'singer': 1.11177116e-07, 'commissioner': 1.1010435e-07, 'author': 1.078354e-07, 'assassin': 1.0719082e-07, 'correspondent': 1.0603273e-07, 'editor': 1.0522816e-07, 'writer': 1.0464302e-07, 'teacher': 1.0449673e-07, 'solicitor_general': 1.0384454e-07, 'prisoner': 1.02838825e-07, 'therapist': 1.0161978e-07, 'strategist': 1.0083959e-07, 'trader': 9.9913116e-08, 'radiologist': 9.964492e-08, 'magician': 9.94255e-08, 'musician': 9.927921e-08, 'warden': 9.7718825e-08, 'serviceman': 9.723121e-08, 'lawyer': 9.540264e-08, 'marshal': 9.518321e-08, 'advocate': 9.493941e-08, 'saxophonist': 9.4256734e-08, 'foreman': 9.411045e-08, 'cleric': 9.2257494e-08, 'bureaucrat': 9.094093e-08, 'envoy': 9.05996e-08, 'observer': 8.978283e-08, 'priest': 8.923426e-08, 'caretaker': 8.850283e-08, 'surgeon': 8.81615e-08, 'crusader': 8.6211024e-08, 'collector': 8.426055e-08, 'pianist': 8.3870454e-08, 'organist': 8.3827786e-08, 'director': 8.369979e-08, 'analyst': 8.260265e-08, 'baron': 8.216379e-08, 'farmer': 8.201751e-08, 'investment_banker': 8.193217e-08, 'cardiologist': 8.123731e-08, 'major_leaguer': 8.074969e-08, 'sheriff_deputy': 8.045712e-08, 'diplomat': 8.031083e-08, 'infielder': 7.971502e-08, 'cabbie': 7.863007e-08, 'landlord': 7.743388e-08, 'trucker': 7.733636e-08, 'pollster': 7.714131e-08, 'baker': 7.655616e-08, 'lifeguard': 7.567846e-08, 'novelist': 7.445941e-08, 'photojournalist': 7.289903e-08, 'dentist': 7.265521e-08, 'fisherman': 7.099732e-08, 'cop': 7.0460935e-08, 'protester': 7.036341e-08, 'ballplayer': 7.033903e-08, 'drug_addict': 6.933941e-08, 'economist': 6.8742075e-08, 'physicist': 6.8266644e-08, 'secretary': 6.7657126e-08, 'judge': 6.701103e-08, 'waiter': 6.651122e-08, 'mediator': 6.5340934e-08, 'missionary': 6.479236e-08, 'archaeologist': 6.46217e-08, 'astronaut': 6.441445e-08, 'narrator': 6.35855e-08, 'citizen': 6.30796e-08, 'actor': 6.304913e-08, 'archbishop': 6.280531e-08, 'photographer': 6.236646e-08, 'athletic_director': 6.104989e-08, 'hooker': 6.0915795e-08, 'lawmaker': 6.080608e-08, 'neurologist': 6.063541e-08, 'physician': 6.017218e-08, 'guitarist': 5.8953127e-08, 'psychologist': 5.856303e-08, 'butcher': 5.641751e-08, 'civil_servant': 5.5978653e-08, 'restaurateur': 5.5588558e-08, 'associate_professor': 5.5100934e-08, 'councilor': 5.4564552e-08, 'inventor': 5.385751e-08, 'poet': 5.2540937e-08, 'midfielder': 5.14438e-08, 'rabbi': 5.0127223e-08, 'magistrate': 4.8591225e-08, 'attorney': 4.822551e-08, 'barrister': 4.820113e-08, 'taxi_driver': 4.7640366e-08, 'shopkeeper': 4.7055224e-08, 'freelance_writer': 4.6762654e-08, 'mathematician': 4.666513e-08, 'chef': 4.6226276e-08, 'confesses': 4.610437e-08, 'janitor': 4.5933703e-08, 'welder': 4.3544368e-08, 'mobster': 4.330056e-08, 'pastor': 4.3105512e-08, 'investigator': 4.2910465e-08, 'barber': 4.2715417e-08, 'boss': 4.174018e-08, 'politician': 4.1654843e-08, 'entertainer': 4.0374847e-08, 'conductor': 3.9442277e-08, 'parliamentarian': 3.8229324e-08, 'performer': 3.793675e-08, 'valedictorian': 3.783923e-08, 'sportswriter': 3.7449134e-08, 'pediatrician': 3.6668943e-08, 'accountant': 3.6473896e-08, 'saint': 3.645866e-08, 'legislator': 3.593751e-08, 'comic': 3.5842277e-08, 'character': 3.384075e-08, 'soft_spoken': 3.2182847e-08, 'lecturer': 3.181713e-08, 'lyricist': 3.150018e-08, 'negotiator': 3.150018e-08, 'firefighter': 3.1341706e-08, 'commander': 3.061637e-08, 'naturalist': 3.0183614e-08, 'biologist': 3.008609e-08, 'worker': 3.0061706e-08, 'campaigner': 3.0037324e-08, 'professor': 3.0037324e-08, 'technician': 2.9842276e-08, 'doctor': 2.8867039e-08, 'planner': 2.8257515e-08, 'tutor': 2.740418e-08, 'educator': 2.7379802e-08, 'sculptor': 2.4819803e-08, 'disc_jockey': 2.477104e-08, 'composer': 2.4600373e-08, 'associate_dean': 2.3795803e-08, 'principal': 2.3747042e-08, 'ranger': 2.2771804e-08, 'crooner': 2.2723043e-08, 'acquaintance': 2.139428e-08, 'bartender': 2.0284947e-08, 'scientist': 2.0211804e-08, 'filmmaker': 2.00899e-08, 'fireman': 2.00899e-08, 'senator': 2.00899e-08, 'alter_ego': 1.9992374e-08, 'protagonist': 1.960228e-08, 'philosopher': 1.9407233e-08, 'artiste': 1.9212186e-08, 'singer_songwriter': 1.9065899e-08, 'soloist': 1.7993138e-08, 'dean': 1.7554282e-08, 'bishop': 1.7505519e-08, 'mechanic': 1.523809e-08, 'painter': 1.5043044e-08, 'philanthropist': 1.4335996e-08, 'hitman': 1.3799616e-08, 'goalkeeper': 1.3263235e-08, 'substitute': 1.2580568e-08, 'trooper': 1.13615215e-08, 'sailor': 1.0605711e-08, 'doctoral_student': 9.849902e-09, 'comedian': 9.80114e-09, 'plastic_surgeon': 9.7523785e-09, 'officer': 7.72876e-09, 'soldier': 6.96076e-09, 'dermatologist': 6.241522e-09, 'journalist': 5.6076175e-09, 'captain': 4.90057e-09, 'consultant': 4.3885704e-09, 'cab_driver': 2.5599993e-09, 'sergeant': 1.9992374e-09, 'scholar': 1.0727615e-09, 'alderman': 9.752378e-10, 'butler': 6.70476e-10, 'broker': 3.6571418e-10, 'electrician': 4.876189e-11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvqz1x6CPj68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}