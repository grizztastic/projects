{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SFDL_HW2_Keras_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGoIKGIA72Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idQVHnX28Z36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load(\"train_X.npy\")\n",
        "y_train = np.load(\"train_y.npy\")\n",
        "val_X = np.load(\"val_X.npy\")\n",
        "val_Y = np.load(\"val_y.npy\")\n",
        "test_X = np.load(\"public_test_X.npy\")\n",
        "test_Y = np.load(\"public_test_y.npy\")\n",
        "private_test_X = np.load(\"private_test_X.npy\")\n",
        "train_norm = x_train.astype('float32')\n",
        "test_norm = test_X.astype('float32')\n",
        "val_norm = val_X.astype('float32')\n",
        "val_y = val_Y.astype('float32')\n",
        "private_test_X = private_test_X.astype('float32')\n",
        "# normalize to range 0-1\n",
        "private_test_norm = private_test_X / 255.0\n",
        "train_norm = train_norm / 255.0\n",
        "test_norm = test_norm / 255.0\n",
        "val_norm_x = val_norm / 255.0\n",
        "one_hot_val_y = keras.utils.to_categorical(val_y)\n",
        "private_test = private_test_X / 255.0\n",
        "one_hot_test_Y = keras.utils.to_categorical(test_Y)\n",
        "one_hot_train_Y = keras.utils.to_categorical(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwubNHPq8aK-",
        "colab_type": "code",
        "outputId": "fd4716e0-5a62-45a2-f1ac-46958ebf7acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szQANU_S8aPe",
        "colab_type": "code",
        "outputId": "46374534-c301-466b-8e03-afbd211c0b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3),kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCHvc5lzDBz0",
        "colab_type": "code",
        "outputId": "d252b1d5-9ec1-4741-dfa4-f1ce42da31c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compile model\n",
        "epochs = 30\n",
        "lrate = 0.0001\n",
        "#decay = lrate/epochs\n",
        "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#callback = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(train_norm, one_hot_train_Y, validation_data=(val_norm_x, one_hot_val_y), epochs=epochs, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_61 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_66 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 3,045,674\n",
            "Trainable params: 3,044,778\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Train on 47000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "47000/47000 [==============================] - 13s 267us/step - loss: 1.6023 - acc: 0.4242 - val_loss: 1.3054 - val_acc: 0.5290\n",
            "Epoch 2/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 1.1149 - acc: 0.6057 - val_loss: 0.9345 - val_acc: 0.6790\n",
            "Epoch 3/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.8919 - acc: 0.6890 - val_loss: 0.8129 - val_acc: 0.7230\n",
            "Epoch 4/30\n",
            "47000/47000 [==============================] - 7s 160us/step - loss: 0.7633 - acc: 0.7371 - val_loss: 0.8743 - val_acc: 0.7030\n",
            "Epoch 5/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.6693 - acc: 0.7678 - val_loss: 0.6338 - val_acc: 0.7950\n",
            "Epoch 6/30\n",
            "47000/47000 [==============================] - 7s 160us/step - loss: 0.5940 - acc: 0.7938 - val_loss: 0.6086 - val_acc: 0.7900\n",
            "Epoch 7/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.5319 - acc: 0.8156 - val_loss: 0.5852 - val_acc: 0.7960\n",
            "Epoch 8/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.4806 - acc: 0.8355 - val_loss: 0.5566 - val_acc: 0.8150\n",
            "Epoch 9/30\n",
            "47000/47000 [==============================] - 8s 162us/step - loss: 0.4298 - acc: 0.8518 - val_loss: 0.5694 - val_acc: 0.8260\n",
            "Epoch 10/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.3991 - acc: 0.8618 - val_loss: 0.5823 - val_acc: 0.8090\n",
            "Epoch 11/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.3577 - acc: 0.8748 - val_loss: 0.5903 - val_acc: 0.8280\n",
            "Epoch 12/30\n",
            "47000/47000 [==============================] - 8s 162us/step - loss: 0.3237 - acc: 0.8880 - val_loss: 0.5579 - val_acc: 0.8290\n",
            "Epoch 13/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.3027 - acc: 0.8959 - val_loss: 0.5828 - val_acc: 0.8270\n",
            "Epoch 14/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.2795 - acc: 0.9060 - val_loss: 0.5336 - val_acc: 0.8430\n",
            "Epoch 15/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.2510 - acc: 0.9145 - val_loss: 0.5786 - val_acc: 0.8320\n",
            "Epoch 16/30\n",
            "47000/47000 [==============================] - 8s 162us/step - loss: 0.2390 - acc: 0.9185 - val_loss: 0.6488 - val_acc: 0.8470\n",
            "Epoch 17/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.2231 - acc: 0.9252 - val_loss: 0.5543 - val_acc: 0.8440\n",
            "Epoch 18/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.2071 - acc: 0.9304 - val_loss: 0.5837 - val_acc: 0.8410\n",
            "Epoch 19/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.2027 - acc: 0.9308 - val_loss: 0.5405 - val_acc: 0.8430\n",
            "Epoch 20/30\n",
            "47000/47000 [==============================] - 7s 160us/step - loss: 0.1856 - acc: 0.9371 - val_loss: 0.6583 - val_acc: 0.8310\n",
            "Epoch 21/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1814 - acc: 0.9381 - val_loss: 0.5869 - val_acc: 0.8460\n",
            "Epoch 22/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.1711 - acc: 0.9430 - val_loss: 0.6752 - val_acc: 0.8310\n",
            "Epoch 23/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1636 - acc: 0.9448 - val_loss: 0.5403 - val_acc: 0.8470\n",
            "Epoch 24/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.1581 - acc: 0.9477 - val_loss: 0.5720 - val_acc: 0.8420\n",
            "Epoch 25/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.1538 - acc: 0.9487 - val_loss: 0.6091 - val_acc: 0.8510\n",
            "Epoch 26/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.1511 - acc: 0.9501 - val_loss: 0.6534 - val_acc: 0.8540\n",
            "Epoch 27/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1508 - acc: 0.9499 - val_loss: 0.6483 - val_acc: 0.8280\n",
            "Epoch 28/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1391 - acc: 0.9548 - val_loss: 0.6214 - val_acc: 0.8330\n",
            "Epoch 29/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1398 - acc: 0.9530 - val_loss: 0.6518 - val_acc: 0.8370\n",
            "Epoch 30/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1337 - acc: 0.9570 - val_loss: 0.6139 - val_acc: 0.8370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9c86a75c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_jYugi6MQ-o",
        "colab_type": "code",
        "outputId": "55f2b769-19dc-434a-9531-498a50911f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_norm, one_hot_train_Y, validation_data=(val_norm_x, one_hot_val_y), epochs=epochs, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1297 - acc: 0.9579 - val_loss: 0.5604 - val_acc: 0.8440\n",
            "Epoch 2/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1303 - acc: 0.9573 - val_loss: 0.5827 - val_acc: 0.8600\n",
            "Epoch 3/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.1269 - acc: 0.9584 - val_loss: 0.5902 - val_acc: 0.8480\n",
            "Epoch 4/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.1196 - acc: 0.9607 - val_loss: 0.6892 - val_acc: 0.8250\n",
            "Epoch 5/30\n",
            "47000/47000 [==============================] - 7s 158us/step - loss: 0.1275 - acc: 0.9591 - val_loss: 0.6662 - val_acc: 0.8330\n",
            "Epoch 6/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1225 - acc: 0.9603 - val_loss: 0.5966 - val_acc: 0.8620\n",
            "Epoch 7/30\n",
            "47000/47000 [==============================] - 8s 162us/step - loss: 0.1189 - acc: 0.9619 - val_loss: 0.6232 - val_acc: 0.8430\n",
            "Epoch 8/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1180 - acc: 0.9619 - val_loss: 0.5915 - val_acc: 0.8450\n",
            "Epoch 9/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1130 - acc: 0.9643 - val_loss: 0.6509 - val_acc: 0.8440\n",
            "Epoch 10/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1083 - acc: 0.9650 - val_loss: 0.6344 - val_acc: 0.8440\n",
            "Epoch 11/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1061 - acc: 0.9650 - val_loss: 0.6331 - val_acc: 0.8510\n",
            "Epoch 12/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1103 - acc: 0.9650 - val_loss: 0.6115 - val_acc: 0.8470\n",
            "Epoch 13/30\n",
            "47000/47000 [==============================] - 8s 162us/step - loss: 0.1032 - acc: 0.9663 - val_loss: 0.7357 - val_acc: 0.8430\n",
            "Epoch 14/30\n",
            "47000/47000 [==============================] - 8s 161us/step - loss: 0.1129 - acc: 0.9642 - val_loss: 0.6474 - val_acc: 0.8570\n",
            "Epoch 15/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.1026 - acc: 0.9653 - val_loss: 0.6052 - val_acc: 0.8490\n",
            "Epoch 16/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.0985 - acc: 0.9684 - val_loss: 0.6405 - val_acc: 0.8450\n",
            "Epoch 17/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0980 - acc: 0.9680 - val_loss: 0.6459 - val_acc: 0.8450\n",
            "Epoch 18/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.1028 - acc: 0.9665 - val_loss: 0.6374 - val_acc: 0.8560\n",
            "Epoch 19/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0990 - acc: 0.9672 - val_loss: 0.5971 - val_acc: 0.8600\n",
            "Epoch 20/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.0983 - acc: 0.9681 - val_loss: 0.5642 - val_acc: 0.8480\n",
            "Epoch 21/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0965 - acc: 0.9693 - val_loss: 0.6170 - val_acc: 0.8510\n",
            "Epoch 22/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0945 - acc: 0.9696 - val_loss: 0.6506 - val_acc: 0.8530\n",
            "Epoch 23/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.0978 - acc: 0.9689 - val_loss: 0.5766 - val_acc: 0.8660\n",
            "Epoch 24/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.0932 - acc: 0.9705 - val_loss: 0.5862 - val_acc: 0.8520\n",
            "Epoch 25/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0888 - acc: 0.9704 - val_loss: 0.7014 - val_acc: 0.8460\n",
            "Epoch 26/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0919 - acc: 0.9701 - val_loss: 0.6264 - val_acc: 0.8680\n",
            "Epoch 27/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0923 - acc: 0.9696 - val_loss: 0.5525 - val_acc: 0.8570\n",
            "Epoch 28/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0918 - acc: 0.9696 - val_loss: 0.5301 - val_acc: 0.8690\n",
            "Epoch 29/30\n",
            "47000/47000 [==============================] - 7s 159us/step - loss: 0.0882 - acc: 0.9722 - val_loss: 0.6283 - val_acc: 0.8600\n",
            "Epoch 30/30\n",
            "47000/47000 [==============================] - 8s 160us/step - loss: 0.0915 - acc: 0.9707 - val_loss: 0.6454 - val_acc: 0.8540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9c8c09438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6-BeYsMmxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = model.predict_classes(private_test_norm)\n",
        "def save_csv(x, filename=\"submission.csv\"):\n",
        "    \"\"\"save_csv Save the input into csv file\n",
        "\n",
        "    Arguments:\n",
        "        x {np.ndarray} -- input array\n",
        "\n",
        "    Keyword Arguments:\n",
        "        filename {str} -- The file name (default: {\"submission.csv\"})\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Input data structure is not np.ndarray\n",
        "    \"\"\"\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = x.flatten()\n",
        "        np.savetxt(filename, x, delimiter=',',fmt='%i')\n",
        "    else:\n",
        "        raise ValueError(\"The input is not an np.ndarray\")\n",
        "save_csv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8fH5vwb-8Nz",
        "colab_type": "code",
        "outputId": "7a481f03-2dae-41a2-e25f-e2140b26a97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctJQgQMz-_aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load(\"train_X.npy\").astype('float32')/255.0\n",
        "y_train = np.load(\"train_y.npy\").astype('float32')\n",
        "onehot_train_Y = to_categorical(y_train)\n",
        "val_X = np.load(\"val_X.npy\").astype('float32')/255.0\n",
        "val_Y = np.load(\"val_y.npy\").astype('float32')\n",
        "onehot_val_Y = to_categorical(val_Y)\n",
        "private_test_X = np.load(\"private_test_X.npy\").astype('float32')/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gue9zBz0-_sE",
        "colab_type": "code",
        "outputId": "2e2677d2-dfc8-4aff-d470-45ecda531338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3),kernel_initializer='he_uniform', activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfMmy8sS-_2x",
        "colab_type": "code",
        "outputId": "8a16764b-bd82-46ca-b8af-44d5d5a4a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 30\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(x_train, onehot_train_Y, validation_data=(val_X, onehot_val_Y), epochs=epochs, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 3,045,674\n",
            "Trainable params: 3,044,778\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 47000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "47000/47000 [==============================] - 14s 298us/step - loss: 1.6216 - acc: 0.4178 - val_loss: 1.2474 - val_acc: 0.5680\n",
            "Epoch 2/30\n",
            "47000/47000 [==============================] - 6s 136us/step - loss: 1.1301 - acc: 0.6019 - val_loss: 1.0553 - val_acc: 0.6500\n",
            "Epoch 3/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.9093 - acc: 0.6841 - val_loss: 0.9627 - val_acc: 0.6630\n",
            "Epoch 4/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.7695 - acc: 0.7333 - val_loss: 0.7712 - val_acc: 0.7370\n",
            "Epoch 5/30\n",
            "47000/47000 [==============================] - 6s 136us/step - loss: 0.6706 - acc: 0.7691 - val_loss: 0.6902 - val_acc: 0.7600\n",
            "Epoch 6/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.6055 - acc: 0.7931 - val_loss: 0.6392 - val_acc: 0.7860\n",
            "Epoch 7/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.5414 - acc: 0.8151 - val_loss: 0.5962 - val_acc: 0.8160\n",
            "Epoch 8/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.4872 - acc: 0.8309 - val_loss: 0.5662 - val_acc: 0.8180\n",
            "Epoch 9/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.4488 - acc: 0.8457 - val_loss: 0.5866 - val_acc: 0.8080\n",
            "Epoch 10/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.4050 - acc: 0.8597 - val_loss: 0.6131 - val_acc: 0.8070\n",
            "Epoch 11/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.3720 - acc: 0.8707 - val_loss: 0.6051 - val_acc: 0.7980\n",
            "Epoch 12/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.3420 - acc: 0.8816 - val_loss: 0.5417 - val_acc: 0.8330\n",
            "Epoch 13/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.3151 - acc: 0.8906 - val_loss: 0.5439 - val_acc: 0.8260\n",
            "Epoch 14/30\n",
            "47000/47000 [==============================] - 6s 136us/step - loss: 0.2813 - acc: 0.9024 - val_loss: 0.5448 - val_acc: 0.8230\n",
            "Epoch 15/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.2669 - acc: 0.9090 - val_loss: 0.5977 - val_acc: 0.8300\n",
            "Epoch 16/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.2448 - acc: 0.9156 - val_loss: 0.5760 - val_acc: 0.8270\n",
            "Epoch 17/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.2296 - acc: 0.9213 - val_loss: 0.6394 - val_acc: 0.8260\n",
            "Epoch 18/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.2198 - acc: 0.9249 - val_loss: 0.5449 - val_acc: 0.8420\n",
            "Epoch 19/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.2044 - acc: 0.9306 - val_loss: 0.5659 - val_acc: 0.8280\n",
            "Epoch 20/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1949 - acc: 0.9351 - val_loss: 0.5234 - val_acc: 0.8560\n",
            "Epoch 21/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.1863 - acc: 0.9372 - val_loss: 0.5266 - val_acc: 0.8570\n",
            "Epoch 22/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1744 - acc: 0.9397 - val_loss: 0.6743 - val_acc: 0.8320\n",
            "Epoch 23/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1705 - acc: 0.9428 - val_loss: 0.6595 - val_acc: 0.8430\n",
            "Epoch 24/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.1575 - acc: 0.9473 - val_loss: 0.5561 - val_acc: 0.8550\n",
            "Epoch 25/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.1603 - acc: 0.9467 - val_loss: 0.5668 - val_acc: 0.8410\n",
            "Epoch 26/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1554 - acc: 0.9478 - val_loss: 0.5938 - val_acc: 0.8540\n",
            "Epoch 27/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1502 - acc: 0.9490 - val_loss: 0.5976 - val_acc: 0.8360\n",
            "Epoch 28/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1442 - acc: 0.9513 - val_loss: 0.5824 - val_acc: 0.8490\n",
            "Epoch 29/30\n",
            "47000/47000 [==============================] - 6s 134us/step - loss: 0.1368 - acc: 0.9547 - val_loss: 0.6678 - val_acc: 0.8380\n",
            "Epoch 30/30\n",
            "47000/47000 [==============================] - 6s 135us/step - loss: 0.1360 - acc: 0.9554 - val_loss: 0.6501 - val_acc: 0.8360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4913be0748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}